{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e65364f-289c-4d1a-9798-525faf3d6c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (1.70.0)\n",
      "Requirement already satisfied: langchain in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (0.3.23)\n",
      "Requirement already satisfied: pinecone-client in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (6.0.0)\n",
      "Requirement already satisfied: PyMuPDF in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (1.25.5)\n",
      "Requirement already satisfied: pypdf in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (5.4.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (2.11.2)\n",
      "Requirement already satisfied: sniffio in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.24)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone-client) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone-client) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone-client) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai langchain pinecone-client PyMuPDF pypdf python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391a8c15-ec14-426f-ae36-4aa3f5bfd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8609b09f-2372-4159-8545-cd2bda279a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "PINECONE_API_KEY = \"pcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\"\n",
    "PINECONE_ENV = \"us-east-1\"  \n",
    "PINECONE_INDEX_NAME = \"collab-chat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3ac9a1-d8aa-4bb0-b9b5-2e223445242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daivikpurani/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/daivikpurani/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ✅ Imports\n",
    "import fitz  # PyMuPDF\n",
    "from pinecone import Pinecone\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83ccfe-8384-494f-9ae8-aac55e180485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d94c4ae-a479-4547-aed7-c75f0bbbbc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Create an instance of the Pinecone client\n",
    "pc = Pinecone(api_key=\"pcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\")\n",
    "\n",
    "# Check if the specified index exists; if not, create it.\n",
    "# You can choose 'cosine' (common for embeddings) or another metric as needed.\n",
    "if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=1536,  # 1536 dimensions are used by OpenAI's embeddings\n",
    "        metric='cosine',\n",
    "        # Optionally, if you're using a serverless configuration:\n",
    "        spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    "    )\n",
    "\n",
    "# Retrieve the index instance\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca082011-3d08-4c9f-9f55-483928911706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collab-chat', 'collab-chat-mini']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb342b4-91e7-4835-b391-df21c29079d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Function to extract text from a PDF\n",
    "def load_pdf_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da082973-02ff-4518-9a53-88d4f1735fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_and_upload(text):\n",
    "    # 1. Split the text into chunks\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    texts = splitter.split_text(text)\n",
    "\n",
    "    # 2. Create the embedder using your OpenAI API key\n",
    "    embedder = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # 3. Import LangChain's Pinecone wrapper and initialize it using the correct parameter name.\n",
    "    from langchain.vectorstores import Pinecone  # using LangChain's Pinecone wrapper\n",
    "    vectorstore = Pinecone.from_existing_index(\n",
    "        index_name=PINECONE_INDEX_NAME,   # your Pinecone index name\n",
    "        embedding=embedder.embed_query,     # note use of 'embedding' instead of 'embedding_function'\n",
    "        text_key=\"text\" ,\n",
    "        api_key=PINECONE_API_KEY# the field name where text is stored in your index\n",
    "    )\n",
    "    vectorstore._use_inference = False\n",
    "    # 4. Add the text chunks to the vector store\n",
    "    vectorstore.add_texts(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d47711c-bccb-4906-993c-cbdd905caa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\\nReinforcement Learning\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\\nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\\nvised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\\nThrough RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\\nreasoning behaviors. However, it encounters challenges such as poor readability, and language\\nmixing. To address these issues and further enhance reasoning performance, we introduce\\nDeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\\nR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\\nresearch community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\\n(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\\nAIME 2024\\n(Pass@1)\\nCodeforces\\n(Percentile)\\nGPQA Diamond\\n(Pass@1)\\nMATH-500\\n(Pass@1)\\nMMLU\\n(Pass@1)\\nSWE-bench Verified\\n(Resolved)\\n0\\n20\\n40\\n60\\n80\\n100\\nAccuracy / Percentile (%)\\n79.8\\n96.3\\n71.5\\n97.3\\n90.8\\n49.2\\n79.2\\n96.6\\n75.7\\n96.4\\n91.8\\n48.9\\n72.6\\n90.6\\n62.1\\n94.3\\n87.4\\n36.8\\n63.6\\n93.4\\n60.0\\n90.0\\n85.2\\n41.6\\n39.2\\n58.7\\n59.1\\n90.2\\n88.5\\n42.0\\nDeepSeek-R1\\nOpenAI-o1-1217\\nDeepSeek-R1-32B\\nOpenAI-o1-mini\\nDeepSeek-V3\\nFigure 1 | Benchmark performance of DeepSeek-R1.\\narXiv:2501.12948v1  [cs.CL]  22 Jan 2025\\nContents\\n1\\nIntroduction\\n3\\n1.1\\nContributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n4\\n1.2\\nSummary of Evaluation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n4\\n2\\nApproach\\n5\\n2.1\\nOverview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n5\\n2.2\\nDeepSeek-R1-Zero: Reinforcement Learning on the Base Model . . . . . . . . . .\\n5\\n2.2.1\\nReinforcement Learning Algorithm\\n. . . . . . . . . . . . . . . . . . . . . .\\n5\\n2.2.2\\nReward Modeling\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n6\\n2.2.3\\nTraining Template\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n6\\n2.2.4\\nPerformance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero\\n6\\n2.3\\nDeepSeek-R1: Reinforcement Learning with Cold Start . . . . . . . . . . . . . . .\\n9\\n2.3.1\\nCold Start . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\n2.3.2\\nReasoning-oriented Reinforcement Learning . . . . . . . . . . . . . . . . .\\n10\\n2.3.3\\nRejection Sampling and Supervised Fine-Tuning . . . . . . . . . . . . . . .\\n10\\n2.3.4\\nReinforcement Learning for all Scenarios . . . . . . . . . . . . . . . . . . .\\n11\\n2.4\\nDistillation: Empower Small Models with Reasoning Capability . . . . . . . . . .\\n11\\n3\\nExperiment\\n11\\n3.1\\nDeepSeek-R1 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n13\\n3.2\\nDistilled Model Evaluation\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n14\\n4\\nDiscussion\\n14\\n4.1\\nDistillation v.s. Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . .\\n14\\n4.2\\nUnsuccessful Attempts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n15\\n5\\nConclusion, Limitations, and Future Work\\n16\\nA Contributions and Acknowledgments\\n20\\n2\\n1. Introduction\\nIn recent years, Large Language Models (LLMs) have been undergoing rapid iteration and\\nevolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap\\ntowards Artificial General Intelligence (AGI).\\nRecently, post-training has emerged as an important component of the full training pipeline.\\nIt has been shown to enhance accuracy on reasoning tasks, align with social values, and adapt\\nto user preferences, all while requiring relatively minimal computational resources against\\npre-training. In the context of reasoning capabilities, OpenAI’s o1 (OpenAI, 2024b) series models\\nwere the first to introduce inference-time scaling by increasing the length of the Chain-of-\\nThought reasoning process. This approach has achieved significant improvements in various\\nreasoning tasks, such as mathematics, coding, and scientific reasoning. However, the challenge\\nof effective test-time scaling remains an open question for the research community. Several prior\\nworks have explored various approaches, including process-based reward models (Lightman\\net al., 2023; Uesato et al., 2022; Wang et al., 2023), reinforcement learning (Kumar et al., 2024),\\nand search algorithms such as Monte Carlo Tree Search and Beam Search (Feng et al., 2024; Trinh\\net al., 2024; Xin et al., 2024). However, none of these methods has achieved general reasoning\\nperformance comparable to OpenAI’s o1 series models.\\nIn this paper, we take the first step toward improving language model reasoning capabilities\\nusing pure reinforcement learning (RL). Our goal is to explore the potential of LLMs to develop\\nreasoning capabilities without any supervised data, focusing on their self-evolution through\\na pure RL process. Specifically, we use DeepSeek-V3-Base as the base model and employ\\nGRPO (Shao et al., 2024) as the RL framework to improve model performance in reasoning.\\nDuring training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting\\nreasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance\\non reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to\\n71.0%, and with majority voting, the score further improves to 86.7%, matching the performance\\nof OpenAI-o1-0912.\\nHowever, DeepSeek-R1-Zero encounters challenges such as poor readability, and language\\nmixing. To address these issues and further enhance reasoning performance, we introduce\\nDeepSeek-R1, which incorporates a small amount of cold-start data and a multi-stage training\\npipeline. Specifically, we begin by collecting thousands of cold-start data to fine-tune the\\nDeepSeek-V3-Base model. Following this, we perform reasoning-oriented RL like DeepSeek-R1-\\nZero. Upon nearing convergence in the RL process, we create new SFT data through rejection\\nsampling on the RL checkpoint, combined with supervised data from DeepSeek-V3 in domains\\nsuch as writing, factual QA, and self-cognition, and then retrain the DeepSeek-V3-Base model.\\nAfter fine-tuning with the new data, the checkpoint undergoes an additional RL process, taking\\ninto account prompts from all scenarios. After these steps, we obtained a checkpoint referred to\\nas DeepSeek-R1, which achieves performance on par with OpenAI-o1-1217.\\nWe further explore distillation from DeepSeek-R1 to smaller dense models. Using Qwen2.5-\\n32B (Qwen, 2024b) as the base model, direct distillation from DeepSeek-R1 outperforms applying\\nRL on it. This demonstrates that the reasoning patterns discovered by larger base models are cru-\\ncial for improving reasoning capabilities. We open-source the distilled Qwen and Llama (Dubey\\net al., 2024) series. Notably, our distilled 14B model outperforms state-of-the-art open-source\\nQwQ-32B-Preview (Qwen, 2024a) by a large margin, and the distilled 32B and 70B models set a\\nnew record on the reasoning benchmarks among dense models.\\n3\\n1.1. Contributions\\nPost-Training: Large-Scale Reinforcement Learning on the Base Model\\n• We directly apply RL to the base model without relying on supervised fine-tuning (SFT) as\\na preliminary step. This approach allows the model to explore chain-of-thought (CoT) for\\nsolving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-\\nR1-Zero demonstrates capabilities such as self-verification, reflection, and generating\\nlong CoTs, marking a significant milestone for the research community. Notably, it is the\\nfirst open research to validate that reasoning capabilities of LLMs can be incentivized\\npurely through RL, without the need for SFT. This breakthrough paves the way for future\\nadvancements in this area.\\n• We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL\\nstages aimed at discovering improved reasoning patterns and aligning with human pref-\\nerences, as well as two SFT stages that serve as the seed for the model’s reasoning and\\nnon-reasoning capabilities. We believe the pipeline will benefit the industry by creating\\nbetter models.\\nDistillation: Smaller Models Can Be Powerful Too\\n• We demonstrate that the reasoning patterns of larger models can be distilled into smaller\\nmodels, resulting in better performance compared to the reasoning patterns discovered\\nthrough RL on small models. The open source DeepSeek-R1, as well as its API, will benefit\\nthe research community to distill better smaller models in the future.\\n• Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models\\nthat are widely used in the research community. The evaluation results demonstrate that\\nthe distilled smaller dense models perform exceptionally well on benchmarks. DeepSeek-\\nR1-Distill-Qwen-7B achieves 55.5% on AIME 2024, surpassing QwQ-32B-Preview. Addi-\\ntionally, DeepSeek-R1-Distill-Qwen-32B scores 72.6% on AIME 2024, 94.3% on MATH-500,\\nand 57.2% on LiveCodeBench. These results significantly outperform previous open-\\nsource models and are comparable to o1-mini. We open-source distilled 1.5B, 7B, 8B, 14B,\\n32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community.\\n1.2. Summary of Evaluation Results\\n• Reasoning tasks: (1) DeepSeek-R1 achieves a score of 79.8% Pass@1 on AIME 2024, slightly\\nsurpassing OpenAI-o1-1217. On MATH-500, it attains an impressive score of 97.3%,\\nperforming on par with OpenAI-o1-1217 and significantly outperforming other models. (2)\\nOn coding-related tasks, DeepSeek-R1 demonstrates expert level in code competition tasks,\\nas it achieves 2,029 Elo rating on Codeforces outperforming 96.3% human participants in\\nthe competition. For engineering-related tasks, DeepSeek-R1 performs slightly better than\\nDeepSeek-V3, which could help developers in real world tasks.\\n• Knowledge: On benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-\\nR1 achieves outstanding results, significantly outperforming DeepSeek-V3 with scores\\nof 90.8% on MMLU, 84.0% on MMLU-Pro, and 71.5% on GPQA Diamond. While its\\nperformance is slightly below that of OpenAI-o1-1217 on these benchmarks, DeepSeek-R1\\nsurpasses other closed-source models, demonstrating its competitive edge in educational\\ntasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3,\\ndemonstrating its capability in handling fact-based queries. A similar trend is observed\\nwhere OpenAI-o1 surpasses 4o on this benchmark.\\n4\\n• Others: DeepSeek-R1 also excels in a wide range of tasks, including creative writing,\\ngeneral question answering, editing, summarization, and more. It achieves an impressive\\nlength-controlled win-rate of 87.6% on AlpacaEval 2.0 and a win-rate of 92.3% on Are-\\nnaHard, showcasing its strong ability to intelligently handle non-exam-oriented queries.\\nAdditionally, DeepSeek-R1 demonstrates outstanding performance on tasks requiring\\nlong-context understanding, substantially outperforming DeepSeek-V3 on long-context\\nbenchmarks.\\n2. Approach\\n2.1. Overview\\nPrevious work has heavily relied on large amounts of supervised data to enhance model\\nperformance. In this study, we demonstrate that reasoning capabilities can be significantly\\nimproved through large-scale reinforcement learning (RL), even without using supervised\\nfine-tuning (SFT) as a cold start. Furthermore, performance can be further enhanced with\\nthe inclusion of a small amount of cold-start data. In the following sections, we present: (1)\\nDeepSeek-R1-Zero, which applies RL directly to the base model without any SFT data, and\\n(2) DeepSeek-R1, which applies RL starting from a checkpoint fine-tuned with thousands of\\nlong Chain-of-Thought (CoT) examples. 3) Distill the reasoning capability from DeepSeek-R1 to\\nsmall dense models.\\n2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\\nReinforcement learning has demonstrated significant effectiveness in reasoning tasks, as ev-\\nidenced by our previous works (Shao et al., 2024; Wang et al., 2023). However, these works\\nheavily depended on supervised data, which are time-intensive to gather. In this section, we\\nexplore the potential of LLMs to develop reasoning capabilities without any supervised data,\\nfocusing on their self-evolution through a pure reinforcement learning process. We start with a\\nbrief overview of our RL algorithm, followed by the presentation of some exciting results, and\\nhope this provides the community with valuable insights.\\n2.2.1. Reinforcement Learning Algorithm\\nGroup Relative Policy Optimization\\nIn order to save the training costs of RL, we adopt Group\\nRelative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is\\ntypically the same size as the policy model, and estimates the baseline from group scores instead.\\nSpecifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, · · · , 𝑜𝐺} from the old\\npolicy 𝜋𝜃𝑜𝑙𝑑and then optimizes the policy model 𝜋𝜃by maximizing the following objective:\\nJ𝐺𝑅𝑃𝑂(𝜃) = E[𝑞∼𝑃(𝑄), {𝑜𝑖}𝐺\\n𝑖=1 ∼𝜋𝜃𝑜𝑙𝑑(𝑂|𝑞)]\\n1\\n𝐺\\n𝐺\\n∑︁\\n𝑖=1\\n\\x12\\nmin\\n\\x12 𝜋𝜃(𝑜𝑖|𝑞)\\n𝜋𝜃𝑜𝑙𝑑(𝑜𝑖|𝑞) 𝐴𝑖, clip\\n\\x12 𝜋𝜃(𝑜𝑖|𝑞)\\n𝜋𝜃𝑜𝑙𝑑(𝑜𝑖|𝑞) , 1 −𝜀, 1 + 𝜀\\n\\x13\\n𝐴𝑖\\n\\x13\\n−𝛽D𝐾𝐿\\n\\x00𝜋𝜃||𝜋𝑟𝑒𝑓\\n\\x01\\x13\\n,\\n(1)\\nD𝐾𝐿\\n\\x00𝜋𝜃||𝜋𝑟𝑒𝑓\\n\\x01 =\\n𝜋𝑟𝑒𝑓(𝑜𝑖|𝑞)\\n𝜋𝜃(𝑜𝑖|𝑞) −log\\n𝜋𝑟𝑒𝑓(𝑜𝑖|𝑞)\\n𝜋𝜃(𝑜𝑖|𝑞) −1,\\n(2)\\nwhere 𝜀and 𝛽are hyper-parameters, and 𝐴𝑖is the advantage, computed using a group of\\nrewards {𝑟1, 𝑟2, . . . , 𝑟𝐺} corresponding to the outputs within each group:\\n𝐴𝑖= 𝑟𝑖−m𝑒𝑎𝑛({𝑟1, 𝑟2, · · · , 𝑟𝐺})\\ns𝑡𝑑({𝑟1, 𝑟2, · · · , 𝑟𝐺})\\n.\\n(3)\\n5\\nA conversation between User and Assistant. The user asks a question, and the Assistant solves it.\\nThe assistant first thinks about the reasoning process in the mind and then provides the user\\nwith the answer. The reasoning process and answer are enclosed within <think> </think> and\\n<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\\n<answer> answer here </answer>. User: prompt. Assistant:\\nTable 1 | Template for DeepSeek-R1-Zero. prompt will be replaced with the specific reasoning\\nquestion during training.\\n2.2.2. Reward Modeling\\nThe reward is the source of the training signal, which decides the optimization direction of RL.\\nTo train DeepSeek-R1-Zero, we adopt a rule-based reward system that mainly consists of two\\ntypes of rewards:\\n• Accuracy rewards: The accuracy reward model evaluates whether the response is correct.\\nFor example, in the case of math problems with deterministic results, the model is required\\nto provide the final answer in a specified format (e.g., within a box), enabling reliable\\nrule-based verification of correctness. Similarly, for LeetCode problems, a compiler can be\\nused to generate feedback based on predefined test cases.\\n• Format rewards: In addition to the accuracy reward model, we employ a format reward\\nmodel that enforces the model to put its thinking process between ‘<think>’ and ‘</think>’\\ntags.\\nWe do not apply the outcome or process neural reward model in developing DeepSeek-R1-Zero,\\nbecause we find that the neural reward model may suffer from reward hacking in the large-scale\\nreinforcement learning process, and retraining the reward model needs additional training\\nresources and it complicates the whole training pipeline.\\n2.2.3. Training Template\\nTo train DeepSeek-R1-Zero, we begin by designing a straightforward template that guides\\nthe base model to adhere to our specified instructions. As depicted in Table 1, this template\\nrequires DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer.\\nWe intentionally limit our constraints to this structural format, avoiding any content-specific\\nbiases—such as mandating reflective reasoning or promoting particular problem-solving strate-\\ngies—to ensure that we can accurately observe the model’s natural progression during the RL\\nprocess.\\n2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero\\nPerformance of DeepSeek-R1-Zero\\nFigure 2 depicts the performance trajectory of DeepSeek-\\nR1-Zero on the AIME 2024 benchmark throughout the RL training process. As illustrated,\\nDeepSeek-R1-Zero demonstrates a steady and consistent enhancement in performance as the\\nRL training advances. Notably, the average pass@1 score on AIME 2024 shows a significant\\nincrease, jumping from an initial 15.6% to an impressive 71.0%, reaching performance levels\\ncomparable to OpenAI-o1-0912. This significant improvement highlights the efficacy of our RL\\nalgorithm in optimizing the model’s performance over time.\\nTable 2 provides a comparative analysis between DeepSeek-R1-Zero and OpenAI’s o1-0912\\nmodels across a variety of reasoning-related benchmarks. The findings reveal that RL empowers\\n6\\nModel\\nAIME 2024\\nMATH-500\\nGPQA\\nLiveCode\\nCodeForces\\nDiamond\\nBench\\npass@1\\ncons@64\\npass@1\\npass@1\\npass@1\\nrating\\nOpenAI-o1-mini\\n63.6\\n80.0\\n90.0\\n60.0\\n53.8\\n1820\\nOpenAI-o1-0912\\n74.4\\n83.3\\n94.8\\n77.3\\n63.4\\n1843\\nDeepSeek-R1-Zero\\n71.0\\n86.7\\n95.9\\n73.3\\n50.0\\n1444\\nTable 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related\\nbenchmarks.\\nFigure 2 | AIME accuracy of DeepSeek-R1-Zero during training. For each question, we sample\\n16 responses and calculate the overall average accuracy to ensure a stable evaluation.\\nDeepSeek-R1-Zero to attain robust reasoning capabilities without the need for any supervised\\nfine-tuning data. This is a noteworthy achievement, as it underscores the model’s ability to\\nlearn and generalize effectively through RL alone. Additionally, the performance of DeepSeek-\\nR1-Zero can be further augmented through the application of majority voting. For example,\\nwhen majority voting is employed on the AIME benchmark, DeepSeek-R1-Zero’s performance\\nescalates from 71.0% to 86.7%, thereby exceeding the performance of OpenAI-o1-0912. The\\nability of DeepSeek-R1-Zero to achieve such competitive performance, both with and without\\nmajority voting, highlights its strong foundational capabilities and its potential for further\\nadvancements in reasoning tasks.\\nSelf-evolution Process of DeepSeek-R1-Zero\\nThe self-evolution process of DeepSeek-R1-Zero\\nis a fascinating demonstration of how RL can drive a model to improve its reasoning capabilities\\nautonomously. By initiating RL directly from the base model, we can closely monitor the model’s\\nprogression without the influence of the supervised fine-tuning stage. This approach provides\\na clear view of how the model evolves over time, particularly in terms of its ability to handle\\ncomplex reasoning tasks.\\nAs depicted in Figure 3, the thinking time of DeepSeek-R1-Zero shows consistent improve-\\n7\\nFigure 3 | The average response length of DeepSeek-R1-Zero on the training set during the RL\\nprocess. DeepSeek-R1-Zero naturally learns to solve reasoning tasks with more thinking time.\\nment throughout the training process. This improvement is not the result of external adjustments\\nbut rather an intrinsic development within the model. DeepSeek-R1-Zero naturally acquires the\\nability to solve increasingly complex reasoning tasks by leveraging extended test-time compu-\\ntation. This computation ranges from generating hundreds to thousands of reasoning tokens,\\nallowing the model to explore and refine its thought processes in greater depth.\\nOne of the most remarkable aspects of this self-evolution is the emergence of sophisticated\\nbehaviors as the test-time computation increases. Behaviors such as reflection—where the model\\nrevisits and reevaluates its previous steps—and the exploration of alternative approaches to\\nproblem-solving arise spontaneously. These behaviors are not explicitly programmed but instead\\nemerge as a result of the model’s interaction with the reinforcement learning environment. This\\nspontaneous development significantly enhances DeepSeek-R1-Zero’s reasoning capabilities,\\nenabling it to tackle more challenging tasks with greater efficiency and accuracy.\\nAha Moment of DeepSeek-R1-Zero\\nA particularly intriguing phenomenon observed during\\nthe training of DeepSeek-R1-Zero is the occurrence of an “aha moment”. This moment, as\\nillustrated in Table 3, occurs in an intermediate version of the model. During this phase,\\nDeepSeek-R1-Zero learns to allocate more thinking time to a problem by reevaluating its initial\\napproach. This behavior is not only a testament to the model’s growing reasoning abilities\\nbut also a captivating example of how reinforcement learning can lead to unexpected and\\nsophisticated outcomes.\\nThis moment is not only an “aha moment” for the model but also for the researchers\\nobserving its behavior. It underscores the power and beauty of reinforcement learning: rather\\nthan explicitly teaching the model on how to solve a problem, we simply provide it with the\\nright incentives, and it autonomously develops advanced problem-solving strategies. The\\n“aha moment” serves as a powerful reminder of the potential of RL to unlock new levels of\\nintelligence in artificial systems, paving the way for more autonomous and adaptive models in\\nthe future.\\n8\\nQuestion: If 𝑎> 1, then the sum of the real solutions of\\n√︁\\n𝑎−√\\n𝑎+ 𝑥= 𝑥is equal to\\nResponse: <think>\\nTo solve the equation\\n√︁\\n𝑎−√\\n𝑎+ 𝑥= 𝑥, let’s start by squaring both · · ·\\n\\x10√︁\\n𝑎−√\\n𝑎+ 𝑥\\n\\x112\\n= 𝑥2 =⇒𝑎−√\\n𝑎+ 𝑥= 𝑥2.\\nRearrange to isolate the inner square root term:\\n(𝑎−𝑥2)2 = 𝑎+ 𝑥=⇒𝑎2 −2𝑎𝑥2 + (𝑥2)2 = 𝑎+ 𝑥=⇒𝑥4 −2𝑎𝑥2 −𝑥+ (𝑎2 −𝑎) = 0\\n. . .\\nWait, wait. Wait. That’s an aha moment I can flag here.\\nLet’s reevaluate this step-by-step to identify if the correct sum can be · · ·\\nWe started with the equation:\\n√︁\\n𝑎−√\\n𝑎+ 𝑥= 𝑥\\nFirst, let’s square both sides:\\n𝑎−√\\n𝑎+ 𝑥= 𝑥2 =⇒√\\n𝑎+ 𝑥= 𝑎−𝑥2\\nNext, I could square both sides again, treating the equation: · · ·\\n. . .\\nTable 3 | An interesting “aha moment” of an intermediate version of DeepSeek-R1-Zero. The\\nmodel learns to rethink using an anthropomorphic tone. This is also an aha moment for us,\\nallowing us to witness the power and beauty of reinforcement learning.\\nDrawback of DeepSeek-R1-Zero\\nAlthough DeepSeek-R1-Zero exhibits strong reasoning\\ncapabilities and autonomously develops unexpected and powerful reasoning behaviors, it faces\\nseveral issues. For instance, DeepSeek-R1-Zero struggles with challenges like poor readability,\\nand language mixing. To make reasoning processes more readable and share them with the\\nopen community, we explore DeepSeek-R1, a method that utilizes RL with human-friendly\\ncold-start data.\\n2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\\nInspired by the promising results of DeepSeek-R1-Zero, two natural questions arise: 1) Can\\nreasoning performance be further improved or convergence accelerated by incorporating a small\\namount of high-quality data as a cold start? 2) How can we train a user-friendly model that\\nnot only produces clear and coherent Chains of Thought (CoT) but also demonstrates strong\\ngeneral capabilities? To address these questions, we design a pipeline to train DeepSeek-R1. The\\npipeline consists of four stages, outlined as follows.\\n2.3.1. Cold Start\\nUnlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from\\nthe base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data\\nto fine-tune the model as the initial RL actor. To collect such data, we have explored several\\napproaches: using few-shot prompting with a long CoT as an example, directly prompting\\nmodels to generate detailed answers with reflection and verification, gathering DeepSeek-R1-\\nZero outputs in a readable format, and refining the results through post-processing by human\\nannotators.\\nIn this work, we collect thousands of cold-start data to fine-tune the DeepSeek-V3-Base as\\nthe starting point for RL. Compared to DeepSeek-R1-Zero, the advantages of cold start data\\n9\\ninclude:\\n• Readability: A key limitation of DeepSeek-R1-Zero is that its content is often not suitable\\nfor reading. Responses may mix multiple languages or lack markdown formatting to\\nhighlight answers for users. In contrast, when creating cold-start data for DeepSeek-R1,\\nwe design a readable pattern that includes a summary at the end of each response and\\nfilters out responses that are not reader-friendly. Here, we define the output format as\\n|special_token|<reasoning_process>|special_token|<summary>, where the reasoning\\nprocess is the CoT for the query, and the summary is used to summarize the reasoning\\nresults.\\n• Potential: By carefully designing the pattern for cold-start data with human priors, we\\nobserve better performance against DeepSeek-R1-Zero. We believe the iterative training is\\na better way for reasoning models.\\n2.3.2. Reasoning-oriented Reinforcement Learning\\nAfter fine-tuning DeepSeek-V3-Base on the cold start data, we apply the same large-scale\\nreinforcement learning training process as employed in DeepSeek-R1-Zero. This phase focuses\\non enhancing the model’s reasoning capabilities, particularly in reasoning-intensive tasks such\\nas coding, mathematics, science, and logic reasoning, which involve well-defined problems with\\nclear solutions. During the training process, we observe that CoT often exhibits language mixing,\\nparticularly when RL prompts involve multiple languages. To mitigate the issue of language\\nmixing, we introduce a language consistency reward during RL training, which is calculated\\nas the proportion of target language words in the CoT. Although ablation experiments show\\nthat such alignment results in a slight degradation in the model’s performance, this reward\\naligns with human preferences, making it more readable. Finally, we combine the accuracy of\\nreasoning tasks and the reward for language consistency by directly summing them to form the\\nfinal reward. We then apply RL training on the fine-tuned model until it achieves convergence\\non reasoning tasks.\\n2.3.3. Rejection Sampling and Supervised Fine-Tuning\\nWhen reasoning-oriented RL converges, we utilize the resulting checkpoint to collect SFT\\n(Supervised Fine-Tuning) data for the subsequent round. Unlike the initial cold-start data, which\\nprimarily focuses on reasoning, this stage incorporates data from other domains to enhance the\\nmodel’s capabilities in writing, role-playing, and other general-purpose tasks. Specifically, we\\ngenerate the data and fine-tune the model as described below.\\nReasoning data\\nWe curate reasoning prompts and generate reasoning trajectories by perform-\\ning rejection sampling from the checkpoint from the above RL training. In the previous stage,\\nwe only included data that could be evaluated using rule-based rewards. However, in this stage,\\nwe expand the dataset by incorporating additional data, some of which use a generative reward\\nmodel by feeding the ground-truth and model predictions into DeepSeek-V3 for judgment.\\nAdditionally, because the model output is sometimes chaotic and difficult to read, we have\\nfiltered out chain-of-thought with mixed languages, long parapraphs, and code blocks. For\\neach prompt, we sample multiple responses and retain only the correct ones. In total, we collect\\nabout 600k reasoning related training samples.\\n10\\nNon-Reasoning data\\nFor non-reasoning data, such as writing, factual QA, self-cognition,\\nand translation, we adopt the DeepSeek-V3 pipeline and reuse portions of the SFT dataset of\\nDeepSeek-V3. For certain non-reasoning tasks, we call DeepSeek-V3 to generate a potential\\nchain-of-thought before answering the question by prompting. However, for simpler queries,\\nsuch as “hello” we do not provide a CoT in response. In the end, we collected a total of\\napproximately 200k training samples that are unrelated to reasoning.\\nWe fine-tune DeepSeek-V3-Base for two epochs using the above curated dataset of about\\n800k samples.\\n2.3.4. Reinforcement Learning for all Scenarios\\nTo further align the model with human preferences, we implement a secondary reinforcement\\nlearning stage aimed at improving the model’s helpfulness and harmlessness while simultane-\\nously refining its reasoning capabilities. Specifically, we train the model using a combination\\nof reward signals and diverse prompt distributions. For reasoning data, we adhere to the\\nmethodology outlined in DeepSeek-R1-Zero, which utilizes rule-based rewards to guide the\\nlearning process in math, code, and logical reasoning domains. For general data, we resort to\\nreward models to capture human preferences in complex and nuanced scenarios. We build\\nupon the DeepSeek-V3 pipeline and adopt a similar distribution of preference pairs and train-\\ning prompts. For helpfulness, we focus exclusively on the final summary, ensuring that the\\nassessment emphasizes the utility and relevance of the response to the user while minimizing\\ninterference with the underlying reasoning process. For harmlessness, we evaluate the entire\\nresponse of the model, including both the reasoning process and the summary, to identify and\\nmitigate any potential risks, biases, or harmful content that may arise during the generation\\nprocess. Ultimately, the integration of reward signals and diverse data distributions enables us\\nto train a model that excels in reasoning while prioritizing helpfulness and harmlessness.\\n2.4. Distillation: Empower Small Models with Reasoning Capability\\nTo equip more efficient smaller models with reasoning capabilities like DeepSeek-R1, we directly\\nfine-tuned open-source models like Qwen (Qwen, 2024b) and Llama (AI@Meta, 2024) using\\nthe 800k samples curated with DeepSeek-R1, as detailed in §2.3.3. Our findings indicate that\\nthis straightforward distillation method significantly enhances the reasoning abilities of smaller\\nmodels. The base models we use here are Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, Qwen2.5-\\n14B, Qwen2.5-32B, Llama-3.1-8B, and Llama-3.3-70B-Instruct. We select Llama-3.3 because its\\nreasoning capability is slightly better than that of Llama-3.1.\\nFor distilled models, we apply only SFT and do not include an RL stage, even though\\nincorporating RL could substantially boost model performance. Our primary goal here is to\\ndemonstrate the effectiveness of the distillation technique, leaving the exploration of the RL\\nstage to the broader research community.\\n3. Experiment\\nBenchmarks\\nWe evaluate models on MMLU (Hendrycks et al., 2020), MMLU-Redux (Gema\\net al., 2024), MMLU-Pro (Wang et al., 2024), C-Eval (Huang et al., 2023), and CMMLU (Li et al.,\\n2023), IFEval (Zhou et al., 2023), FRAMES (Krishna et al., 2024), GPQA Diamond (Rein et al.,\\n2023), SimpleQA (OpenAI, 2024c), C-SimpleQA (He et al., 2024), SWE-Bench Verified (OpenAI,\\n11\\n2024d), Aider 1, LiveCodeBench (Jain et al., 2024) (2024-08 – 2025-01), Codeforces 2, Chinese\\nNational High School Mathematics Olympiad (CNMO 2024)3, and American Invitational Math-\\nematics Examination 2024 (AIME 2024) (MAA, 2024). In addition to standard benchmarks, we\\nalso evaluate our models on open-ended generation tasks using LLMs as judges. Specifically, we\\nadhere to the original configurations of AlpacaEval 2.0 (Dubois et al., 2024) and Arena-Hard (Li\\net al., 2024), which leverage GPT-4-Turbo-1106 as judges for pairwise comparisons. Here, we\\nonly feed the final summary to evaluation to avoid the length bias. For distilled models, we\\nreport representative results on AIME 2024, MATH-500, GPQA Diamond, Codeforces, and\\nLiveCodeBench.\\nEvaluation Prompts\\nFollowing the setup in DeepSeek-V3, standard benchmarks such as\\nMMLU, DROP, GPQA Diamond, and SimpleQA are evaluated using prompts from the simple-\\nevals framework. For MMLU-Redux, we adopt the Zero-Eval prompt format (Lin, 2024) in a\\nzero-shot setting. In terms of MMLU-Pro, C-Eval and CLUE-WSC, since the original prompts\\nare few-shot, we slightly modify the prompt to the zero-shot setting. The CoT in few-shot\\nmay hurt the performance of DeepSeek-R1. Other datasets follow their original evaluation\\nprotocols with default prompts provided by their creators. For code and math benchmarks, the\\nHumanEval-Mul dataset covers eight mainstream programming languages (Python, Java, C++,\\nC#, JavaScript, TypeScript, PHP, and Bash). Model performance on LiveCodeBench is evaluated\\nusing CoT format, with data collected between August 2024 and January 2025. The Codeforces\\ndataset is evaluated using problems from 10 Div.2 contests along with expert-crafted test cases,\\nafter which the expected ratings and percentages of competitors are calculated. SWE-Bench\\nverified results are obtained via the agentless framework (Xia et al., 2024). AIDER-related\\nbenchmarks are measured using a \"diff\" format. DeepSeek-R1 outputs are capped at a maximum\\nof 32,768 tokens for each benchmark.\\nBaselines\\nWe conduct comprehensive evaluations against several strong baselines, including\\nDeepSeek-V3, Claude-Sonnet-3.5-1022, GPT-4o-0513, OpenAI-o1-mini, and OpenAI-o1-1217.\\nSince accessing the OpenAI-o1-1217 API is challenging in mainland China, we report its perfor-\\nmance based on official reports. For distilled models, we also compare the open-source model\\nQwQ-32B-Preview (Qwen, 2024a).\\nEvaluation Setup\\nWe set the maximum generation length to 32,768 tokens for the models.\\nWe found that using greedy decoding to evaluate long-output reasoning models results in\\nhigher repetition rates and significant variability across different checkpoints. Therefore, we\\ndefault to pass@𝑘evaluation (Chen et al., 2021) and report pass@1 using a non-zero temperature.\\nSpecifically, we use a sampling temperature of 0.6 and a top-𝑝value of 0.95 to generate 𝑘\\nresponses (typically between 4 and 64, depending on the test set size) for each question. Pass@1\\nis then calculated as\\npass@1 = 1\\n𝑘\\n𝑘\\n∑︁\\n𝑖=1\\n𝑝𝑖,\\nwhere 𝑝𝑖denotes the correctness of the 𝑖-th response. This method provides more reliable\\nperformance estimates. For AIME 2024, we also report consensus (majority vote) results (Wang\\net al., 2022) using 64 samples, denoted as cons@64.\\n1https://aider.chat\\n2https://codeforces.com\\n3https://www.cms.org.cn/Home/comp/comp/cid/12.html\\n12\\n3.1. DeepSeek-R1 Evaluation\\nBenchmark (Metric)\\nClaude-3.5- GPT-4o DeepSeek OpenAI OpenAI DeepSeek\\nSonnet-1022\\n0513\\nV3\\no1-mini o1-1217\\nR1\\nArchitecture\\n-\\n-\\nMoE\\n-\\n-\\nMoE\\n# Activated Params\\n-\\n-\\n37B\\n-\\n-\\n37B\\n# Total Params\\n-\\n-\\n671B\\n-\\n-\\n671B\\nEnglish\\nMMLU (Pass@1)\\n88.3\\n87.2\\n88.5\\n85.2\\n91.8\\n90.8\\nMMLU-Redux (EM)\\n88.9\\n88.0\\n89.1\\n86.7\\n-\\n92.9\\nMMLU-Pro (EM)\\n78.0\\n72.6\\n75.9\\n80.3\\n-\\n84.0\\nDROP (3-shot F1)\\n88.3\\n83.7\\n91.6\\n83.9\\n90.2\\n92.2\\nIF-Eval (Prompt Strict)\\n86.5\\n84.3\\n86.1\\n84.8\\n-\\n83.3\\nGPQA Diamond (Pass@1)\\n65.0\\n49.9\\n59.1\\n60.0\\n75.7\\n71.5\\nSimpleQA (Correct)\\n28.4\\n38.2\\n24.9\\n7.0\\n47.0\\n30.1\\nFRAMES (Acc.)\\n72.5\\n80.5\\n73.3\\n76.9\\n-\\n82.5\\nAlpacaEval2.0 (LC-winrate)\\n52.0\\n51.1\\n70.0\\n57.8\\n-\\n87.6\\nArenaHard (GPT-4-1106)\\n85.2\\n80.4\\n85.5\\n92.0\\n-\\n92.3\\nCode\\nLiveCodeBench (Pass@1-COT)\\n38.9\\n32.9\\n36.2\\n53.8\\n63.4\\n65.9\\nCodeforces (Percentile)\\n20.3\\n23.6\\n58.7\\n93.4\\n96.6\\n96.3\\nCodeforces (Rating)\\n717\\n759\\n1134\\n1820\\n2061\\n2029\\nSWE Verified (Resolved)\\n50.8\\n38.8\\n42.0\\n41.6\\n48.9\\n49.2\\nAider-Polyglot (Acc.)\\n45.3\\n16.0\\n49.6\\n32.9\\n61.7\\n53.3\\nMath\\nAIME 2024 (Pass@1)\\n16.0\\n9.3\\n39.2\\n63.6\\n79.2\\n79.8\\nMATH-500 (Pass@1)\\n78.3\\n74.6\\n90.2\\n90.0\\n96.4\\n97.3\\nCNMO 2024 (Pass@1)\\n13.1\\n10.8\\n43.2\\n67.6\\n-\\n78.8\\nChinese\\nCLUEWSC (EM)\\n85.4\\n87.9\\n90.9\\n89.9\\n-\\n92.8\\nC-Eval (EM)\\n76.7\\n76.0\\n86.5\\n68.9\\n-\\n91.8\\nC-SimpleQA (Correct)\\n55.4\\n58.7\\n68.0\\n40.3\\n-\\n63.7\\nTable 4 | Comparison between DeepSeek-R1 and other representative models.\\nFor education-oriented knowledge benchmarks such as MMLU, MMLU-Pro, and GPQA\\nDiamond, DeepSeek-R1 demonstrates superior performance compared to DeepSeek-V3. This im-\\nprovement is primarily attributed to enhanced accuracy in STEM-related questions, where signif-\\nicant gains are achieved through large-scale reinforcement learning. Additionally, DeepSeek-R1\\nexcels on FRAMES, a long-context-dependent QA task, showcasing its strong document analysis\\ncapabilities. This highlights the potential of reasoning models in AI-driven search and data\\nanalysis tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3,\\ndemonstrating its capability in handling fact-based queries. A similar trend is observed where\\nOpenAI-o1 surpasses GPT-4o on this benchmark. However, DeepSeek-R1 performs worse than\\nDeepSeek-V3 on the Chinese SimpleQA benchmark, primarily due to its tendency to refuse\\nanswering certain queries after safety RL. Without safety RL, DeepSeek-R1 could achieve an\\naccuracy of over 70%.\\nDeepSeek-R1 also delivers impressive results on IF-Eval, a benchmark designed to assess a\\nmodel’s ability to follow format instructions. These improvements can be linked to the inclusion\\nof instruction-following data during the final stages of supervised fine-tuning (SFT) and RL\\ntraining. Furthermore, remarkable performance is observed on AlpacaEval2.0 and ArenaHard,\\nindicating DeepSeek-R1’s strengths in writing tasks and open-domain question answering. Its\\nsignificant outperformance of DeepSeek-V3 underscores the generalization benefits of large-scale\\nRL, which not only boosts reasoning capabilities but also improves performance across diverse\\ndomains. Moreover, the summary lengths generated by DeepSeek-R1 are concise, with an\\naverage of 689 tokens on ArenaHard and 2,218 characters on AlpacaEval 2.0. This indicates that\\n13\\nDeepSeek-R1 avoids introducing length bias during GPT-based evaluations, further solidifying\\nits robustness across multiple tasks.\\nOn math tasks, DeepSeek-R1 demonstrates performance on par with OpenAI-o1-1217,\\nsurpassing other models by a large margin. A similar trend is observed on coding algorithm\\ntasks, such as LiveCodeBench and Codeforces, where reasoning-focused models dominate these\\nbenchmarks. On engineering-oriented coding tasks, OpenAI-o1-1217 outperforms DeepSeek-R1\\non Aider but achieves comparable performance on SWE Verified. We believe the engineering\\nperformance of DeepSeek-R1 will improve in the next version, as the amount of related RL\\ntraining data currently remains very limited.\\n3.2. Distilled Model Evaluation\\nModel\\nAIME 2024\\nMATH-500\\nGPQA\\nLiveCode\\nCodeForces\\nDiamond\\nBench\\npass@1\\ncons@64\\npass@1\\npass@1\\npass@1\\nrating\\nGPT-4o-0513\\n9.3\\n13.4\\n74.6\\n49.9\\n32.9\\n759\\nClaude-3.5-Sonnet-1022\\n16.0\\n26.7\\n78.3\\n65.0\\n38.9\\n717\\nOpenAI-o1-mini\\n63.6\\n80.0\\n90.0\\n60.0\\n53.8\\n1820\\nQwQ-32B-Preview\\n50.0\\n60.0\\n90.6\\n54.5\\n41.9\\n1316\\nDeepSeek-R1-Distill-Qwen-1.5B\\n28.9\\n52.7\\n83.9\\n33.8\\n16.9\\n954\\nDeepSeek-R1-Distill-Qwen-7B\\n55.5\\n83.3\\n92.8\\n49.1\\n37.6\\n1189\\nDeepSeek-R1-Distill-Qwen-14B\\n69.7\\n80.0\\n93.9\\n59.1\\n53.1\\n1481\\nDeepSeek-R1-Distill-Qwen-32B\\n72.6\\n83.3\\n94.3\\n62.1\\n57.2\\n1691\\nDeepSeek-R1-Distill-Llama-8B\\n50.4\\n80.0\\n89.1\\n49.0\\n39.6\\n1205\\nDeepSeek-R1-Distill-Llama-70B\\n70.0\\n86.7\\n94.5\\n65.2\\n57.5\\n1633\\nTable 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on\\nreasoning-related benchmarks.\\nAs shown in Table 5, simply distilling DeepSeek-R1’s outputs enables the efficient DeepSeek-\\nR1-7B (i.e., DeepSeek-R1-Distill-Qwen-7B, abbreviated similarly below) to outperform non-\\nreasoning models like GPT-4o-0513 across the board. DeepSeek-R1-14B surpasses QwQ-32B-\\nPreview on all evaluation metrics, while DeepSeek-R1-32B and DeepSeek-R1-70B significantly\\nexceed o1-mini on most benchmarks. These results demonstrate the strong potential of distilla-\\ntion. Additionally, we found that applying RL to these distilled models yields significant further\\ngains. We believe this warrants further exploration and therefore present only the results of the\\nsimple SFT-distilled models here.\\n4. Discussion\\n4.1. Distillation v.s. Reinforcement Learning\\nIn Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive\\nresults. However, there is still one question left: can the model achieve comparable performance\\nthrough the large-scale RL training discussed in the paper without distillation?\\nTo answer this question, we conduct large-scale RL training on Qwen-32B-Base using math,\\ncode, and STEM data, training for over 10K steps, resulting in DeepSeek-R1-Zero-Qwen-32B. The\\nexperimental results, shown in Table 6, demonstrate that the 32B base model, after large-scale\\n14\\nModel\\nAIME 2024\\nMATH-500\\nGPQA Diamond\\nLiveCodeBench\\npass@1\\ncons@64\\npass@1\\npass@1\\npass@1\\nQwQ-32B-Preview\\n50.0\\n60.0\\n90.6\\n54.5\\n41.9\\nDeepSeek-R1-Zero-Qwen-32B\\n47.0\\n60.0\\n91.6\\n55.0\\n40.2\\nDeepSeek-R1-Distill-Qwen-32B\\n72.6\\n83.3\\n94.3\\n62.1\\n57.2\\nTable 6 | Comparison of distilled and RL Models on Reasoning-Related Benchmarks.\\nRL training, achieves performance on par with QwQ-32B-Preview. However, DeepSeek-R1-\\nDistill-Qwen-32B, which is distilled from DeepSeek-R1, performs significantly better than\\nDeepSeek-R1-Zero-Qwen-32B across all benchmarks.\\nTherefore, we can draw two conclusions: First, distilling more powerful models into smaller\\nones yields excellent results, whereas smaller models relying on the large-scale RL mentioned in\\nthis paper require enormous computational power and may not even achieve the performance\\nof distillation. Second, while distillation strategies are both economical and effective, advancing\\nbeyond the boundaries of intelligence may still require more powerful base models and larger-\\nscale reinforcement learning.\\n4.2. Unsuccessful Attempts\\nIn the early stages of developing DeepSeek-R1, we also encountered failures and setbacks along\\nthe way. We share our failure experiences here to provide insights, but this does not imply that\\nthese approaches are incapable of developing effective reasoning models.\\nProcess Reward Model (PRM)\\nPRM is a reasonable method to guide the model toward better\\napproaches for solving reasoning tasks (Lightman et al., 2023; Uesato et al., 2022; Wang et al.,\\n2023). However, in practice, PRM has three main limitations that may hinder its ultimate suc-\\ncess. First, it is challenging to explicitly define a fine-grain step in general reasoning. Second,\\ndetermining whether the current intermediate step is correct is a challenging task. Automated\\nannotation using models may not yield satisfactory results, while manual annotation is not con-\\nducive to scaling up. Third, once a model-based PRM is introduced, it inevitably leads to reward\\nhacking (Gao et al., 2022), and retraining the reward model needs additional training resources\\nand it complicates the whole training pipeline. In conclusion, while PRM demonstrates a good\\nability to rerank the top-N responses generated by the model or assist in guided search (Snell\\net al., 2024), its advantages are limited compared to the additional computational overhead it\\nintroduces during the large-scale reinforcement learning process in our experiments.\\nMonte Carlo Tree Search (MCTS)\\nInspired by AlphaGo (Silver et al., 2017b) and AlphaZero (Sil-\\nver et al., 2017a), we explored using Monte Carlo Tree Search (MCTS) to enhance test-time\\ncompute scalability. This approach involves breaking answers into smaller parts to allow the\\nmodel to explore the solution space systematically. To facilitate this, we prompt the model to\\ngenerate multiple tags that correspond to specific reasoning steps necessary for the search. For\\ntraining, we first use collected prompts to find answers via MCTS guided by a pre-trained value\\nmodel. Subsequently, we use the resulting question-answer pairs to train both the actor model\\nand the value model, iteratively refining the process.\\nHowever, this approach encounters several challenges when scaling up the training. First,\\nunlike chess, where the search space is relatively well-defined, token generation presents an\\n15\\nexponentially larger search space. To address this, we set a maximum extension limit for each\\nnode, but this can lead to the model getting stuck in local optima. Second, the value model\\ndirectly influences the quality of generation since it guides each step of the search process.\\nTraining a fine-grained value model is inherently difficult, which makes it challenging for the\\nmodel to iteratively improve. While AlphaGo’s core success relied on training a value model to\\nprogressively enhance its performance, this principle proves difficult to replicate in our setup\\ndue to the complexities of token generation.\\nIn conclusion, while MCTS can improve performance during inference when paired with a\\npre-trained value model, iteratively boosting model performance through self-search remains a\\nsignificant challenge.\\n5. Conclusion, Limitations, and Future Work\\nIn this work, we share our journey in enhancing model reasoning abilities through reinforcement\\nlearning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\\ndata, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\\nleveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 achieves\\nperformance comparable to OpenAI-o1-1217 on a range of tasks.\\nWe further explore distillation the reasoning capability to small dense models. We use\\nDeepSeek-R1 as the teacher model to generate 800K training samples, and fine-tune several small\\ndense models. The results are promising: DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o\\nand Claude-3.5-Sonnet on math benchmarks with 28.9% on AIME and 83.9% on MATH. Other\\ndense models also achieve impressive results, significantly outperforming other instruction-\\ntuned models based on the same underlying checkpoints.\\nIn the future, we plan to invest in research across the following directions for DeepSeek-R1.\\n• General Capability: Currently, the capabilities of DeepSeek-R1 fall short of DeepSeek-V3\\nin tasks such as function calling, multi-turn, complex role-playing, and JSON output.\\nMoving forward, we plan to explore how long CoT can be leveraged to enhance tasks in\\nthese fields.\\n• Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which\\nmay result in language mixing issues when handling queries in other languages. For\\ninstance, DeepSeek-R1 might use English for reasoning and responses, even if the query is\\nin a language other than English or Chinese. We aim to address this limitation in future\\nupdates.\\n• Prompting Engineering: When evaluating DeepSeek-R1, we observe that it is sensitive\\nto prompts. Few-shot prompting consistently degrades its performance. Therefore, we\\nrecommend users directly describe the problem and specify the output format using a\\nzero-shot setting for optimal results.\\n• Software Engineering Tasks: Due to the long evaluation times, which impact the effi-\\nciency of the RL process, large-scale RL has not been applied extensively in software\\nengineering tasks. As a result, DeepSeek-R1 has not demonstrated a huge improvement\\nover DeepSeek-V3 on software engineering benchmarks. Future versions will address\\nthis by implementing rejection sampling on software engineering data or incorporating\\nasynchronous evaluations during the RL process to improve efficiency.\\n16\\nReferences\\nAI@Meta. Llama 3.1 model card, 2024. URL https://github.com/meta-llama/llama-m\\nodels/blob/main/models/llama3_1/MODEL_CARD.md.\\nAnthropic. Claude 3.5 sonnet, 2024. URL https://www.anthropic.com/news/claude-3\\n-5-sonnet.\\nM. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda,\\nN. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin,\\nB. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet,\\nF. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss,\\nA. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse,\\nA. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage,\\nM. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and\\nW. Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021.\\nURL https://arxiv.org/abs/2107.03374.\\nA. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten,\\nA. Yang, A. Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024.\\nY. Dubois, B. Galambosi, P. Liang, and T. B. Hashimoto. Length-controlled alpacaeval: A simple\\nway to debias automatic evaluators. arXiv preprint arXiv:2404.04475, 2024.\\nX. Feng, Z. Wan, M. Wen, S. M. McAleer, Y. Wen, W. Zhang, and J. Wang. Alphazero-like\\ntree-search can guide large language model decoding and training, 2024. URL https:\\n//arxiv.org/abs/2309.17179.\\nL. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization, 2022. URL\\nhttps://arxiv.org/abs/2210.10760.\\nA. P. Gema, J. O. J. Leang, G. Hong, A. Devoto, A. C. M. Mancino, R. Saxena, X. He, Y. Zhao,\\nX. Du, M. R. G. Madani, C. Barale, R. McHardy, J. Harris, J. Kaddour, E. van Krieken, and\\nP. Minervini. Are we done with mmlu? CoRR, abs/2406.04127, 2024. URL https://doi.or\\ng/10.48550/arXiv.2406.04127.\\nGoogle. Our next-generation model: Gemini 1.5, 2024. URL https://blog.google/techno\\nlogy/ai/google-gemini-next-generation-model-february-2024.\\nY. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, et al. Chi-\\nnese simpleqa: A chinese factuality evaluation for large language models. arXiv preprint\\narXiv:2411.07140, 2024.\\nD. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring\\nmassive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.\\nY. Huang, Y. Bai, Z. Zhu, J. Zhang, J. Zhang, T. Su, J. Liu, C. Lv, Y. Zhang, J. Lei, et al. C-Eval: A\\nmulti-level multi-discipline chinese evaluation suite for foundation models. arXiv preprint\\narXiv:2305.08322, 2023.\\nN. Jain, K. Han, A. Gu, W. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.\\nLivecodebench: Holistic and contamination free evaluation of large language models for code.\\nCoRR, abs/2403.07974, 2024. URL https://doi.org/10.48550/arXiv.2403.07974.\\n17\\nS. Krishna, K. Krishna, A. Mohananey, S. Schwarcz, A. Stambler, S. Upadhyay, and M. Faruqui.\\nFact, fetch, and reason: A unified evaluation of retrieval-augmented generation. CoRR,\\nabs/2409.12941, 2024. doi: 10.48550/ARXIV.2409.12941. URL https://doi.org/10.485\\n50/arXiv.2409.12941.\\nA. Kumar, V. Zhuang, R. Agarwal, Y. Su, J. D. Co-Reyes, A. Singh, K. Baumli, S. Iqbal, C. Bishop,\\nR. Roelofs, et al. Training language models to self-correct via reinforcement learning. arXiv\\npreprint arXiv:2409.12917, 2024.\\nH. Li, Y. Zhang, F. Koto, Y. Yang, H. Zhao, Y. Gong, N. Duan, and T. Baldwin. CMMLU: Measur-\\ning massive multitask language understanding in Chinese. arXiv preprint arXiv:2306.09212,\\n2023.\\nT. Li, W.-L. Chiang, E. Frick, L. Dunlap, T. Wu, B. Zhu, J. E. Gonzalez, and I. Stoica. From\\ncrowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline. arXiv\\npreprint arXiv:2406.11939, 2024.\\nH. Lightman, V. Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman,\\nI. Sutskever, and K. Cobbe. Let’s verify step by step. arXiv preprint arXiv:2305.20050, 2023.\\nB. Y. Lin. ZeroEval: A Unified Framework for Evaluating Language Models, July 2024. URL\\nhttps://github.com/WildEval/ZeroEval.\\nMAA.\\nAmerican invitational mathematics examination - aime.\\nIn American Invitational\\nMathematics Examination - AIME 2024, February 2024. URL https://maa.org/math\\n-competitions/american-invitational-mathematics-examination-aime.\\nOpenAI. Hello GPT-4o, 2024a. URL https://openai.com/index/hello-gpt-4o/.\\nOpenAI. Learning to reason with llms, 2024b. URL https://openai.com/index/learnin\\ng-to-reason-with-llms/.\\nOpenAI. Introducing SimpleQA, 2024c. URL https://openai.com/index/introducing\\n-simpleqa/.\\nOpenAI. Introducing SWE-bench verified we’re releasing a human-validated subset of swe-\\nbench that more, 2024d. URL https://openai.com/index/introducing-swe-bench\\n-verified/.\\nQwen. Qwq: Reflect deeply on the boundaries of the unknown, 2024a. URL https://qwenlm\\n.github.io/blog/qwq-32b-preview/.\\nQwen. Qwen2.5: A party of foundation models, 2024b. URL https://qwenlm.github.io/b\\nlog/qwen2.5.\\nD. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman.\\nGPQA: A graduate-level google-proof q&a benchmark. arXiv preprint arXiv:2311.12022, 2023.\\nZ. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, and D. Guo. Deepseekmath:\\nPushing the limits of mathematical reasoning in open language models. arXiv preprint\\narXiv:2402.03300, 2024.\\nD. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez, M. Lanctot, L. Sifre,\\nD. Kumaran, T. Graepel, T. P. Lillicrap, K. Simonyan, and D. Hassabis. Mastering chess and\\nshogi by self-play with a general reinforcement learning algorithm. CoRR, abs/1712.01815,\\n2017a. URL http://arxiv.org/abs/1712.01815.\\n18\\nD. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\\nM. Lai, A. Bolton, Y. Chen, T. P. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and\\nD. Hassabis. Mastering the game of go without human knowledge. Nat., 550(7676):354–359,\\n2017b. doi: 10.1038/NATURE24270. URL https://doi.org/10.1038/nature24270.\\nC. Snell, J. Lee, K. Xu, and A. Kumar. Scaling llm test-time compute optimally can be more\\neffective than scaling model parameters, 2024. URL https://arxiv.org/abs/2408.033\\n14.\\nT. Trinh, Y. Wu, Q. Le, H. He, and T. Luong. Solving olympiad geometry without human\\ndemonstrations. Nature, 2024. doi: 10.1038/s41586-023-06747-5.\\nJ. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, and\\nI. Higgins. Solving math word problems with process-and outcome-based feedback. arXiv\\npreprint arXiv:2211.14275, 2022.\\nP. Wang, L. Li, Z. Shao, R. Xu, D. Dai, Y. Li, D. Chen, Y. Wu, and Z. Sui. Math-shepherd: A label-\\nfree step-by-step verifier for llms in mathematical reasoning. arXiv preprint arXiv:2312.08935,\\n2023.\\nX. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery, and D. Zhou.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171, 2022.\\nY. Wang, X. Ma, G. Zhang, Y. Ni, A. Chandra, S. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang, T. Li,\\nM. Ku, K. Wang, A. Zhuang, R. Fan, X. Yue, and W. Chen. Mmlu-pro: A more robust and\\nchallenging multi-task language understanding benchmark. CoRR, abs/2406.01574, 2024.\\nURL https://doi.org/10.48550/arXiv.2406.01574.\\nC. S. Xia, Y. Deng, S. Dunn, and L. Zhang.\\nAgentless: Demystifying llm-based software\\nengineering agents. arXiv preprint, 2024.\\nH. Xin, Z. Z. Ren, J. Song, Z. Shao, W. Zhao, H. Wang, B. Liu, L. Zhang, X. Lu, Q. Du, W. Gao,\\nQ. Zhu, D. Yang, Z. Gou, Z. F. Wu, F. Luo, and C. Ruan. Deepseek-prover-v1.5: Harnessing\\nproof assistant feedback for reinforcement learning and monte-carlo tree search, 2024. URL\\nhttps://arxiv.org/abs/2408.08152.\\nJ. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y. Luan, D. Zhou, and L. Hou. Instruction-following\\nevaluation for large language models. arXiv preprint arXiv:2311.07911, 2023.\\n19\\nAppendix\\nA. Contributions and Acknowledgments\\nCore Contributors\\nDaya Guo\\nDejian Yang\\nHaowei Zhang\\nJunxiao Song\\nRuoyu Zhang\\nRunxin Xu\\nQihao Zhu\\nShirong Ma\\nPeiyi Wang\\nXiao Bi\\nXiaokang Zhang\\nXingkai Yu\\nYu Wu\\nZ.F. Wu\\nZhibin Gou\\nZhihong Shao\\nZhuoshu Li\\nZiyi Gao\\nContributors\\nAixin Liu\\nBing Xue\\nBingxuan Wang\\nBochao Wu\\nBei Feng\\nChengda Lu\\nChenggang Zhao\\nChengqi Deng\\nChong Ruan\\nDamai Dai\\nDeli Chen\\nDongjie Ji\\nErhang Li\\nFangyun Lin\\nFucong Dai\\nFuli Luo*\\nGuangbo Hao\\nGuanting Chen\\nGuowei Li\\nH. Zhang\\nHanwei Xu\\nHonghui Ding\\nHuazuo Gao\\nHui Qu\\nHui Li\\nJianzhong Guo\\nJiashi Li\\nJingchang Chen\\nJingyang Yuan\\nJinhao Tu\\nJunjie Qiu\\nJunlong Li\\nJ.L. Cai\\nJiaqi Ni\\nJian Liang\\nJin Chen\\nKai Dong\\nKai Hu*\\nKaichao You\\nKaige Gao\\nKang Guan\\nKexin Huang\\nKuai Yu\\nLean Wang\\nLecong Zhang\\nLiang Zhao\\nLitong Wang\\nLiyue Zhang\\nLei Xu\\nLeyi Xia\\nMingchuan Zhang\\nMinghua Zhang\\nMinghui Tang\\nMingxu Zhou\\nMeng Li\\nMiaojun Wang\\nMingming Li\\nNing Tian\\nPanpan Huang\\nPeng Zhang\\nQiancheng Wang\\nQinyu Chen\\nQiushi Du\\nRuiqi Ge*\\nRuisong Zhang\\nRuizhe Pan\\nRunji Wang\\nR.J. Chen\\nR.L. Jin\\n20\\nRuyi Chen\\nShanghao Lu\\nShangyan Zhou\\nShanhuang Chen\\nShengfeng Ye\\nShiyu Wang\\nShuiping Yu\\nShunfeng Zhou\\nShuting Pan\\nS.S. Li\\nShuang Zhou\\nShaoqing Wu\\nShengfeng Ye\\nTao Yun\\nTian Pei\\nTianyu Sun\\nT. Wang\\nWangding Zeng\\nWen Liu\\nWenfeng Liang\\nWenjun Gao\\nWenqin Yu*\\nWentao Zhang\\nW.L. Xiao\\nWei An\\nXiaodong Liu\\nXiaohan Wang\\nXiaokang Chen\\nXiaotao Nie\\nXin Cheng\\nXin Liu\\nXin Xie\\nXingchao Liu\\nXinyu Yang\\nXinyuan Li\\nXuecheng Su\\nXuheng Lin\\nX.Q. Li\\nXiangyue Jin\\nXiaojin Shen\\nXiaosha Chen\\nXiaowen Sun\\nXiaoxiang Wang\\nXinnan Song\\nXinyi Zhou\\nXianzu Wang\\nXinxia Shan\\nY.K. Li\\nY.Q. Wang\\nY.X. Wei\\nYang Zhang\\nYanhong Xu\\nYao Li\\nYao Zhao\\nYaofeng Sun\\nYaohui Wang\\nYi Yu\\nYichao Zhang\\nYifan Shi\\nYiliang Xiong\\nYing He\\nYishi Piao\\nYisong Wang\\nYixuan Tan\\nYiyang Ma*\\nYiyuan Liu\\nYongqiang Guo\\nYuan Ou\\nYuduan Wang\\nYue Gong\\nYuheng Zou\\nYujia He\\nYunfan Xiong\\nYuxiang Luo\\nYuxiang You\\nYuxuan Liu\\nYuyang Zhou\\nY.X. Zhu\\nYanping Huang\\nYaohui Li\\nYi Zheng\\nYuchen Zhu\\nYunxian Ma\\nYing Tang\\nYukun Zha\\nYuting Yan\\nZ.Z. Ren\\nZehui Ren\\nZhangli Sha\\nZhe Fu\\nZhean Xu\\nZhenda Xie\\nZhengyan Zhang\\nZhewen Hao\\nZhicheng Ma\\nZhigang Yan\\nZhiyu Wu\\nZihui Gu\\n21\\nZijia Zhu\\nZijun Liu*\\nZilin Li\\nZiwei Xie\\nZiyang Song\\nZizheng Pan\\nZhen Huang\\nZhipeng Xu\\nZhongyu Zhang\\nZhen Zhang\\nWithin each role, authors are listed alphabetically by the first name. Names marked with *\\ndenote individuals who have departed from our team.\\n22\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"/Users/daivikpurani/Desktop/ACAD/Thesis/code/Backend/pdfs/DeepSeekR1.pdf\"\n",
    "\n",
    "text = load_pdf_text(pdf_path)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a3e0c9-40e9-4763-a470-9ea2993a2a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-huggingface in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-huggingface) (0.30.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-huggingface) (0.3.51)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-huggingface) (4.0.2)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-huggingface) (4.50.3)\n",
      "Requirement already satisfied: filelock in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.24)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.11.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from transformers>=4.39.0->langchain-huggingface) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: anyio in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "269f8fda-d222-4b4b-96e2-4a6e7969ca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-pinecone in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-pinecone) (0.3.51)\n",
      "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<3.11,>=3.10 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-pinecone) (3.10.11)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-pinecone) (2.0.2)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-pinecone) (0.3.17)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.3.24)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.11.2)\n",
      "Requirement already satisfied: pytest<9,>=7 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.5)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
      "Requirement already satisfied: syrupy<5,>=4 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.1)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.3.0)\n",
      "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: anyio in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.2.2)\n",
      "Requirement already satisfied: iniconfig in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (1.15.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/daivikpurani/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c09913-f9e2-4ee8-b48c-8a83879e2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# # 1. Load the PDF using PyPDFLoader\n",
    "# loader = PyPDFLoader(pdf_path)\n",
    "# documents = loader.load()\n",
    "\n",
    "# # Optionally, inspect a snippet from the first document page\n",
    "# # print(documents[0].page_content[:500])\n",
    "\n",
    "# # 2. Split the documents into chunks for better embedding granularity\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# # 3. Create embeddings using the HuggingFace model\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "# index_name = \"collab-chat\" \n",
    "# index = pc.Index(index_name)\n",
    "\n",
    "# embeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# embedding_list = []\n",
    "# for i in range(0, len(docs)):\n",
    "#    embedding_list.append(embeddings_model.embed_query(docs[i].page_content))\n",
    "\n",
    "# #embedding_list.append(embeddings_model.embed_query(\"Hello World\"))\n",
    "\n",
    "# index.upsert(\n",
    "#         vectors=[\n",
    "# {\"id\": f\"vec{i+1}\",\n",
    "# \"values\": embedding_list[i],\n",
    "# \"metadata\": {\"text\": docs[i].page_content, 'docIndex': i}\n",
    "# }\n",
    "# ],\n",
    "#      namespace=index_name\n",
    "# )\n",
    "\n",
    "\n",
    "# # # 4. Create the Pinecone vector store from the documents\n",
    "# # vectorstore = PineconeVectorStore.from_documents(\n",
    "# #     docs,\n",
    "# #     api_key=\"pcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\",\n",
    "# #     embedding=embeddings,\n",
    "# #     index_name=index_name,\n",
    "# #     namespace=\"default\",\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# print(\"PDF has been processed, split, and uploaded to the vector store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a262d0f-4965-4e89-b2f5-723de3a400a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daivikpurani/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/daivikpurani/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m PINECONE_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m PINECONE_ENVIRONMENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# e.g. \"us-east1-gcp\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINECONE_ENVIRONMENT\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollab-chat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Create or connect to your index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/deprecation_warnings.py:39\u001b[0m, in \u001b[0;36minit\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "# fix_script.py\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# If the following import doesn't work, you may need:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import pinecone\n",
    "\n",
    "# --------------------------------\n",
    "# 1. Load your PDF with PyPDFLoader\n",
    "# --------------------------------\n",
    "#pdf_path = \"YOUR_PDF_PATH\"  # e.g. \"/path/to/your.pdf\"\n",
    "pdf_path = \"/Users/daivikpurani/Desktop/ACAD/Thesis/code/Backend/pdfs/DeepSeekR1.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# --------------------------------\n",
    "# 2. Split PDF text into chunks\n",
    "# --------------------------------\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Create HuggingFace embeddings\n",
    "# --------------------------------\n",
    "# The model \"all-MiniLM-L6-v2\" is a common compact embedding model\n",
    "# from the sentence-transformers library.\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create embedding vectors from your split docs\n",
    "embedded_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # embed_query() or embed_documents() will produce a list[float]\n",
    "    # for each chunk of text\n",
    "    vector = embeddings_model.embed_query(doc.page_content)\n",
    "    embedded_docs.append({\n",
    "        \"id\": f\"vec{i+1}\",\n",
    "        \"values\": vector,\n",
    "        \"metadata\": {\n",
    "            \"text\": doc.page_content,\n",
    "            \"docIndex\": i\n",
    "        }\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# 4. Initialize and Upsert to Pinecone\n",
    "# --------------------------------\n",
    "PINECONE_API_KEY = \"pcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\"\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\"  # e.g. \"us-east1-gcp\"\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT\n",
    ")\n",
    "\n",
    "index_name = \"collab-chat\"\n",
    "\n",
    "# Create or connect to your index\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=len(embedded_docs[0][\"values\"]))\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Upsert in batches or as a single upsert\n",
    "index.upsert(vectors=embedded_docs, namespace=index_name)\n",
    "\n",
    "print(\"PDF has been processed, split, and uploaded to the vector store!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd6c47e-4cb5-4aca-8938-346128200a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Project Description_submitted version.pdf\n",
      "Processing PDF: DeepSeekR1.pdf\n",
      "Processing PDF: promptengineering_compressed.pdf\n",
      "Processing PDF: promptengineering.pdf\n",
      "Processing PDF: Large Language Models- A Survey.pdf\n",
      "Processing PDF: Zhongetal.-2024-EnhancingtheAnalysisofInterdisciplinaryLearni.pdf\n",
      "Total vectors to upsert: 2204\n",
      "Index 'collab-chat-mini' already exists.\n",
      "Total vectors to upsert: 2204\n",
      "Upserted batch 1 (1000 vectors)\n",
      "Upserted batch 2 (1000 vectors)\n",
      "Upserted batch 3 (204 vectors)\n",
      "All PDFs have been processed, split, and uploaded to the vector store!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 0. Replace these values with your own\n",
    "# ------------------------------------------------\n",
    "PINECONE_API_KEY = \"pcsk_43iJ8f_DVajihnVoW8qE6yTsCRYgFBqgpYQScmV3yWqRs5vhdfnvRwgkm4dkCNq5FRQbmt\"\n",
    "PINECONE_REGION = \"us-east-1\"  # e.g. \"us-west-1\"\n",
    "# Set the folder that contains your PDF files\n",
    "PDF_FOLDER = \"/Users/daivikpurani/Desktop/ACAD/Thesis/code/Backend/pdfs\"\n",
    "\n",
    "INDEX_NAME = \"collab-chat-mini\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "NAMESPACE = \"collab-chat-mini\"\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Initialize the embedding model\n",
    "# ------------------------------------------------\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Process all PDF files in the folder and create vectors\n",
    "# ------------------------------------------------\n",
    "embedded_docs = []  # List to hold vectors from all PDFs\n",
    "\n",
    "# Loop through all files in the PDF folder\n",
    "for file in os.listdir(PDF_FOLDER):\n",
    "    if file.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(PDF_FOLDER, file)\n",
    "        print(f\"Processing PDF: {file}\")\n",
    "        \n",
    "        # Load the PDF\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Split the documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Generate embeddings for each chunk and store with metadata\n",
    "        for i, doc in enumerate(docs):\n",
    "            vector = embeddings_model.embed_query(doc.page_content)\n",
    "            embedded_docs.append({\n",
    "                \"id\": f\"{os.path.splitext(file)[0]}-vec{i+1}\",  # unique id including filename\n",
    "                \"values\": vector,\n",
    "                \"metadata\": {\n",
    "                    \"text\": doc.page_content,\n",
    "                    \"docIndex\": i,\n",
    "                    \"filename\": file\n",
    "                }\n",
    "            })\n",
    "\n",
    "# Check that we have extracted vectors\n",
    "print(f\"Total vectors to upsert: {len(embedded_docs)}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Initialize the Pinecone client and create the index if needed\n",
    "# ------------------------------------------------\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Infer the embedding dimension from the first vector\n",
    "embedding_dim = len(embedded_docs[0][\"values\"])\n",
    "\n",
    "# Check if the index exists; if not, create it.\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"Index '{INDEX_NAME}' does not exist. Creating...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",       # or whichever cloud you're using\n",
    "            region=PINECONE_REGION\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Upsert all vectors into the Pinecone index\n",
    "# ------------------------------------------------\n",
    "batch_size = 1000\n",
    "total_vectors = len(embedded_docs)\n",
    "print(f\"Total vectors to upsert: {total_vectors}\")\n",
    "my_index = pc.Index(INDEX_NAME)\n",
    "\n",
    "for i in range(0, total_vectors, batch_size):\n",
    "    batch = embedded_docs[i : i + batch_size]\n",
    "    my_index.upsert(vectors=batch, namespace=NAMESPACE)\n",
    "    print(f\"Upserted batch {i // batch_size + 1} ({len(batch)} vectors)\")\n",
    "\n",
    "print(\"All PDFs have been processed, split, and uploaded to the vector store!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb4ae4-a364-423b-a165-0a96c2b958b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your query as a text string\n",
    "# query = \"What is deepseek\"\n",
    "\n",
    "# # Perform a similarity search that returns the top 3 most similar documents/chunks\n",
    "# results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# # Print out the results (each result usually contains a page_content attribute and metadata)\n",
    "# print(\"Retrieved Documents:\")\n",
    "# for i, doc in enumerate(results):\n",
    "#     print(f\"\\nResult {i+1}:\\n{doc.page_content}\")\n",
    "# 1. Define your user query\n",
    "\n",
    "query_text = \"What is deepseek\"\n",
    "\n",
    "# 2. Embed the query using the same model as before\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "query_vector = embeddings_model.embed_query(query_text)\n",
    "\n",
    "# 3. Query the Pinecone index\n",
    "response = my_index.query(\n",
    "    vector=query_vector, \n",
    "    top_k=3,                # how many top matches to return\n",
    "    include_metadata=True,  # include the original text or other metadata\n",
    "    namespace=\"collab-chat-mini\" # same namespace you used during upsert\n",
    ")\n",
    "\n",
    "# 4. Inspect the results\n",
    "for match in response.matches:\n",
    "    score = match.score\n",
    "    snippet = match.metadata[\"text\"][:500]  # first 200 characters\n",
    "    doc_index = match.metadata[\"docIndex\"]\n",
    "    print(f\"Score: {score:.4f} | Doc chunk index: {doc_index}\")\n",
    "    print(f\"Snippet: {snippet}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beecdd20-3c41-4cfc-9f55-2e9aac35eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.0.3-cp37-abi3-macosx_11_0_arm64.whl.metadata (494 bytes)\n",
      "Downloading hf_xet-1.0.3-cp37-abi3-macosx_11_0_arm64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "925218bd-edd2-4ed6-b198-6808f3cac117",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m PineconeVectorStore\u001b[38;5;241m.\u001b[39mfrom_documents(docs, embeddings_model, index_name\u001b[38;5;241m=\u001b[39mINDEX_NAME)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Now you can define a retriever for querying\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m})\n\u001b[1;32m     32\u001b[0m docs \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mget_relevant_documents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain the main findings of the paper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m docs \u001b[38;5;129;01min\u001b[39;00m docs:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "# Initialize Pinecone client\n",
    "# pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_REGION)\n",
    "\n",
    "# INDEX_NAME = \"your-index-name\"\n",
    "# NAMESPACE = \"your-namespace\"\n",
    "\n",
    "# Initialize the Hugging Face embedding model\n",
    "# embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Proper vectorstore initialization using the class method\n",
    "# vectorstore = Pinecone.from_existing_index(\n",
    "#     index_name=INDEX_NAME,\n",
    "#     embedding=embeddings_model,\n",
    "#     text_key=\"text\",\n",
    "#     namespace=NAMESPACE\n",
    "# )\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings_model, index_name=INDEX_NAME)\n",
    "\n",
    "# Now you can define a retriever for querying\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "docs = retriever.get_relevant_documents(\"Explain the main findings of the paper\")\n",
    "\n",
    "for docs in docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73ca703a-7a86-4084-97e6-d8887833d91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Mon, 21 Apr 2025 20:51:15 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-envoy-upstream-service-time': '34', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is deepseek\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Search the dense index and rerank the results\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m dr \u001b[38;5;241m=\u001b[39m \u001b[43mdense_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# rerank={\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"model\": \"cohere-rerank-3.5\",\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"rank_fields\": [\"chunk_text\"]\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# }\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Search the sparse index and rerank the results \u001b[39;00m\n\u001b[1;32m     29\u001b[0m sr \u001b[38;5;241m=\u001b[39m sparse_index\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     30\u001b[0m     namespace\u001b[38;5;241m=\u001b[39mNAMESPACE,\n\u001b[1;32m     31\u001b[0m     query\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/utils/error_handling.py:11\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/data/index.py:222\u001b[0m, in \u001b[0;36mIndex.search\u001b[0;34m(self, namespace, query, rerank, fields)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNamespace is required when searching records\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m request \u001b[38;5;241m=\u001b[39m IndexRequestFactory\u001b[38;5;241m.\u001b[39msearch_request(query\u001b[38;5;241m=\u001b[39mquery, rerank\u001b[38;5;241m=\u001b[39mrerank, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_records_namespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/endpoint.py:102\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/core/openapi/db_data/api/vector_operations_api.py:461\u001b[0m, in \u001b[0;36mVectorOperationsApi.__init__.<locals>.__search_records_namespace\u001b[0;34m(self, namespace, search_records_request, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m namespace\n\u001b[1;32m    460\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_records_request\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m search_records_request\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/endpoint.py:134\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m params \u001b[38;5;241m=\u001b[39m EndpointUtils\u001b[38;5;241m.\u001b[39mgather_params(\n\u001b[1;32m    125\u001b[0m     attribute_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map,\n\u001b[1;32m    126\u001b[0m     location_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m HeaderUtil\u001b[38;5;241m.\u001b[39mprepare_headers(headers_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders_map, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masync_threadpool_executor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_check_return_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/api_client.py:300\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreadpool_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    281\u001b[0m         resource_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         _check_type,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api,\n\u001b[1;32m    321\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     ),\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/api_client.py:178\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    182\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/api_client.py:166\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m build_request_url(\n\u001b[1;32m    158\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    159\u001b[0m     processed_path_params\u001b[38;5;241m=\u001b[39mpath_params_tuple,\n\u001b[1;32m    160\u001b[0m     resource_path\u001b[38;5;241m=\u001b[39mresource_path,\n\u001b[1;32m    161\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[1;32m    162\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/api_client.py:380\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(\n\u001b[1;32m    371\u001b[0m         url,\n\u001b[1;32m    372\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(\n\u001b[1;32m    391\u001b[0m         url,\n\u001b[1;32m    392\u001b[0m         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    398\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/rest_utils.py:146\u001b[0m, in \u001b[0;36mRestClientInterface.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mPOST\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    145\u001b[0m ):\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/rest_urllib3.py:260\u001b[0m, in \u001b[0;36mUrllib3RestClient.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# log response body\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mraise_exceptions_or_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pinecone/openapi_support/rest_utils.py:49\u001b[0m, in \u001b[0;36mraise_exceptions_or_return\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m599\u001b[39m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mPineconeApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Date': 'Mon, 21 Apr 2025 20:51:15 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '116', 'Connection': 'keep-alive', 'x-envoy-upstream-service-time': '34', 'server': 'envoy'})\nHTTP response body: {\"error\":{\"code\":\"INVALID_ARGUMENT\",\"message\":\"Integrated inference is not configured for this index\"},\"status\":400}\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "\n",
    "# To get the unique host for an index, \n",
    "# see https://docs.pinecone.io/guides/data/target-an-index\n",
    "dense_index = pc.Index(host=\"https://collab-chat-mini-tc5ntoa.svc.aped-4627-b74a.pinecone.io\")\n",
    "sparse_index = pc.Index(host=\"https://collab-chat-mini-tc5ntoa.svc.aped-4627-b74a.pinecone.io\")\n",
    "\n",
    "# Define the query\n",
    "query = \"what is deepseek\"\n",
    "\n",
    "# Search the dense index and rerank the results\n",
    "dr = dense_index.search(\n",
    "    namespace=\"\",\n",
    "    query={\n",
    "        \"top_k\": 20,\n",
    "        \"inputs\": {\n",
    "            \"text\": query\n",
    "        }\n",
    "    },\n",
    "    # rerank={\n",
    "    #     \"model\": \"cohere-rerank-3.5\",\n",
    "    #     \"rank_fields\": [\"chunk_text\"]\n",
    "    # }\n",
    ")\n",
    "\n",
    "# Search the sparse index and rerank the results \n",
    "sr = sparse_index.search(\n",
    "    namespace=NAMESPACE,\n",
    "    query={\n",
    "        \"top_k\": 20,\n",
    "        \"inputs\": {\n",
    "            \"text\": query\n",
    "        }\n",
    "    },\n",
    "    # rerank={\n",
    "    #     \"model\": \"cohere-rerank-3.5\",\n",
    "    #     \"rank_fields\": [\"chunk_text\"]\n",
    "    # }\n",
    ")\n",
    "\n",
    "# Merge and deduplicate the results\n",
    "def merge_chunks(h1, h2):\n",
    "    \"\"\"Get the unique hits from two search results and return them as single array\"\"\"\n",
    "    h1_ids = [hit['_id'] for hit in h1['result']['hits']]\n",
    "    h2_ids = [hit['_id'] for hit in h2['result']['hits']]\n",
    "    deduped_hits = {hit['_id']: hit for hit in h1['result']['hits'] + h2['result']['hits']}.values()\n",
    "    return sorted(deduped_hits, key=lambda x: x['_score'], reverse=True)\n",
    "\n",
    "merged = merge_chunks(sr, dr)\n",
    "\n",
    "# Print the results\n",
    "print(\"Query\", query)\n",
    "print(\"-----\")\n",
    "for row in mrgc:\n",
    "    print(f\"{row['_id']} {round(row['_score'], 2)} - {row['fields']['chunk_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d328a7c1-9393-49ad-a943-4b84af4d1e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 63},\n",
       "                'collab-chat-mini': {'vector_count': 2277}},\n",
       " 'total_vector_count': 2340,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4247078-583d-4f67-8abb-63e700986ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 63},\n",
       "                'collab-chat-mini': {'vector_count': 2277}},\n",
       " 'total_vector_count': 2340,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1781592f-ee27-4838-9ca7-edc07c198cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'ba3095cc-24e1-4c46-b98a-1a1e0c4171cf',\n",
       "              'score': 0.163480088,\n",
       "              'values': [-0.0669465736,\n",
       "                         0.0200339537,\n",
       "                         0.0280461926,\n",
       "                         0.0307479221,\n",
       "                         0.00262404303,\n",
       "                         -0.0551778786,\n",
       "                         0.0530165695,\n",
       "                         0.102813907,\n",
       "                         -0.0542607978,\n",
       "                         -0.00221465784,\n",
       "                         -0.0333234183,\n",
       "                         -0.025782181,\n",
       "                         -0.0279382449,\n",
       "                         0.012346644,\n",
       "                         0.0640671,\n",
       "                         0.0331562832,\n",
       "                         0.0697986186,\n",
       "                         0.0434547663,\n",
       "                         -0.0989323258,\n",
       "                         -0.0470690355,\n",
       "                         0.081720084,\n",
       "                         0.0192843676,\n",
       "                         0.0473363884,\n",
       "                         0.0693314299,\n",
       "                         -0.0479217693,\n",
       "                         0.00256164931,\n",
       "                         -0.0333153903,\n",
       "                         -0.0245759822,\n",
       "                         0.0651945546,\n",
       "                         -0.00118173531,\n",
       "                         0.0459458306,\n",
       "                         0.134095237,\n",
       "                         0.0360748805,\n",
       "                         0.0516429022,\n",
       "                         -0.0579122491,\n",
       "                         0.0552506447,\n",
       "                         -0.0457694679,\n",
       "                         0.07492847,\n",
       "                         0.0363136716,\n",
       "                         -0.00123501348,\n",
       "                         -0.0316627063,\n",
       "                         -0.0103208534,\n",
       "                         -0.0572452657,\n",
       "                         0.015877381,\n",
       "                         0.0303205252,\n",
       "                         0.0159164313,\n",
       "                         -0.0752294585,\n",
       "                         -0.00993009936,\n",
       "                         -0.0186094064,\n",
       "                         0.100065067,\n",
       "                         -0.0944065377,\n",
       "                         -0.0223511811,\n",
       "                         -0.0693855807,\n",
       "                         0.0669317096,\n",
       "                         0.011441662,\n",
       "                         0.0256650355,\n",
       "                         -0.0190874655,\n",
       "                         -0.03756826,\n",
       "                         0.0266406722,\n",
       "                         -0.0582469031,\n",
       "                         0.0255272724,\n",
       "                         -0.101998769,\n",
       "                         -0.0583411604,\n",
       "                         0.0173624158,\n",
       "                         -0.0198394675,\n",
       "                         -0.0558947623,\n",
       "                         -0.00880558882,\n",
       "                         0.0477502495,\n",
       "                         -0.0279146228,\n",
       "                         0.0111436211,\n",
       "                         0.0121902358,\n",
       "                         0.0507404171,\n",
       "                         -0.102083169,\n",
       "                         0.0306099933,\n",
       "                         0.00850637,\n",
       "                         0.0679876655,\n",
       "                         -0.0323546566,\n",
       "                         -0.0795380771,\n",
       "                         0.0335401297,\n",
       "                         -0.043950662,\n",
       "                         0.0374599695,\n",
       "                         0.0451717936,\n",
       "                         0.0385459475,\n",
       "                         -0.00400581304,\n",
       "                         0.0671450123,\n",
       "                         -0.107872024,\n",
       "                         0.00052922155,\n",
       "                         -0.00233428925,\n",
       "                         -0.023447711,\n",
       "                         0.0252030417,\n",
       "                         -0.0506507158,\n",
       "                         -0.0467914455,\n",
       "                         0.080388844,\n",
       "                         0.0411934704,\n",
       "                         -0.0105258729,\n",
       "                         -0.0273462944,\n",
       "                         -0.0203773621,\n",
       "                         -0.0434517898,\n",
       "                         0.0364272967,\n",
       "                         0.0806930959,\n",
       "                         -0.0160813052,\n",
       "                         0.119454488,\n",
       "                         -0.0475098789,\n",
       "                         -0.0134941041,\n",
       "                         -0.107259281,\n",
       "                         -0.0837432072,\n",
       "                         -0.00193720032,\n",
       "                         -0.0360972919,\n",
       "                         0.0733711943,\n",
       "                         -0.105427109,\n",
       "                         0.0132804215,\n",
       "                         0.00619299198,\n",
       "                         -0.0112111541,\n",
       "                         -0.0836999938,\n",
       "                         -0.0149077922,\n",
       "                         0.00191822811,\n",
       "                         -0.0176902749,\n",
       "                         0.0674511045,\n",
       "                         -0.0995366648,\n",
       "                         0.063386634,\n",
       "                         -0.0431393348,\n",
       "                         0.0126486504,\n",
       "                         0.0364411511,\n",
       "                         0.0166451447,\n",
       "                         0.0238768253,\n",
       "                         -0.0170128122,\n",
       "                         -0.0408214405,\n",
       "                         3.41605271e-33,\n",
       "                         0.0426888205,\n",
       "                         -0.0362367891,\n",
       "                         0.0291640144,\n",
       "                         -0.045956105,\n",
       "                         0.0350445695,\n",
       "                         0.0129508069,\n",
       "                         -0.0547674224,\n",
       "                         -0.0138234627,\n",
       "                         -0.0519745648,\n",
       "                         -0.0210344326,\n",
       "                         0.0237156637,\n",
       "                         0.00527999038,\n",
       "                         0.0271260124,\n",
       "                         0.028971998,\n",
       "                         0.01299782,\n",
       "                         -0.0138038201,\n",
       "                         -0.110393338,\n",
       "                         0.115808338,\n",
       "                         -0.000163849589,\n",
       "                         0.0106849819,\n",
       "                         0.0477469228,\n",
       "                         0.0226739831,\n",
       "                         -0.013255246,\n",
       "                         -0.0271781571,\n",
       "                         -0.0235209949,\n",
       "                         0.0140016899,\n",
       "                         0.00112377212,\n",
       "                         0.027097581,\n",
       "                         0.0344315208,\n",
       "                         0.0228238255,\n",
       "                         -0.0133878402,\n",
       "                         0.00716843829,\n",
       "                         -0.033120431,\n",
       "                         0.0295700282,\n",
       "                         0.0128530813,\n",
       "                         0.00189800444,\n",
       "                         0.058364816,\n",
       "                         -0.0813328177,\n",
       "                         0.0589176901,\n",
       "                         0.0396164916,\n",
       "                         -0.019347284,\n",
       "                         0.00785921421,\n",
       "                         0.104891278,\n",
       "                         -0.057809,\n",
       "                         0.048950579,\n",
       "                         0.00357327471,\n",
       "                         0.0514775887,\n",
       "                         -0.0303652193,\n",
       "                         0.0210565683,\n",
       "                         0.0684358403,\n",
       "                         -0.0327537134,\n",
       "                         -0.00802044664,\n",
       "                         -0.00848827325,\n",
       "                         0.00371978525,\n",
       "                         0.00036838057,\n",
       "                         0.0550171509,\n",
       "                         -0.0186114833,\n",
       "                         -0.00957189593,\n",
       "                         0.0705153644,\n",
       "                         0.0506116524,\n",
       "                         -0.0112723056,\n",
       "                         -0.0456741825,\n",
       "                         -0.0224778634,\n",
       "                         0.0219290275,\n",
       "                         0.0256962311,\n",
       "                         -0.0199057516,\n",
       "                         -0.0745383427,\n",
       "                         -0.0228637941,\n",
       "                         0.0244116746,\n",
       "                         0.0537523963,\n",
       "                         -0.0279592499,\n",
       "                         -0.0155710736,\n",
       "                         -0.0708313808,\n",
       "                         0.0582524613,\n",
       "                         -0.0387628414,\n",
       "                         -0.00155318668,\n",
       "                         0.000179850787,\n",
       "                         0.081555292,\n",
       "                         -0.0590728223,\n",
       "                         0.0249875076,\n",
       "                         -0.0922850072,\n",
       "                         0.00461889291,\n",
       "                         -0.0008274024,\n",
       "                         -0.123910956,\n",
       "                         -0.0830833167,\n",
       "                         0.0169982519,\n",
       "                         0.0629257262,\n",
       "                         -0.101987004,\n",
       "                         0.0496779792,\n",
       "                         0.035822168,\n",
       "                         -0.175825864,\n",
       "                         -0.0154473204,\n",
       "                         -0.149878904,\n",
       "                         -0.00407772325,\n",
       "                         0.0472605154,\n",
       "                         -3.13570906e-33,\n",
       "                         -0.0148651479,\n",
       "                         0.0758411363,\n",
       "                         -0.0882169232,\n",
       "                         0.0879628137,\n",
       "                         0.0518248156,\n",
       "                         -0.0172376335,\n",
       "                         0.0354090929,\n",
       "                         -0.0464792214,\n",
       "                         -0.0178112183,\n",
       "                         0.015627373,\n",
       "                         -0.015473959,\n",
       "                         -0.0630754158,\n",
       "                         -0.0156525411,\n",
       "                         -0.0941764638,\n",
       "                         -0.014045259,\n",
       "                         -0.0108392388,\n",
       "                         -0.0332629271,\n",
       "                         0.0569119528,\n",
       "                         -0.0432295874,\n",
       "                         0.0535971858,\n",
       "                         0.000400570891,\n",
       "                         0.00660960795,\n",
       "                         -0.0459345281,\n",
       "                         0.0641870275,\n",
       "                         0.0895699486,\n",
       "                         0.00731719,\n",
       "                         -0.0544439033,\n",
       "                         0.0222426653,\n",
       "                         0.0479025804,\n",
       "                         -0.0519364215,\n",
       "                         -0.0232056174,\n",
       "                         -0.0979071259,\n",
       "                         -0.0492752045,\n",
       "                         -0.0239932407,\n",
       "                         -0.00989435241,\n",
       "                         -0.0106884744,\n",
       "                         0.115438834,\n",
       "                         -0.0489951558,\n",
       "                         -0.0290612374,\n",
       "                         0.0851424783,\n",
       "                         0.0306441952,\n",
       "                         0.0292136613,\n",
       "                         -0.0749017596,\n",
       "                         0.0207816176,\n",
       "                         -0.0548210107,\n",
       "                         -0.0200794563,\n",
       "                         -0.0646250397,\n",
       "                         -0.0772010908,\n",
       "                         0.00355670019,\n",
       "                         0.00960158091,\n",
       "                         0.0454918034,\n",
       "                         -0.00806712545,\n",
       "                         -0.0157882255,\n",
       "                         0.0402414277,\n",
       "                         0.0349671617,\n",
       "                         -0.122570075,\n",
       "                         0.120139405,\n",
       "                         -0.0116110444,\n",
       "                         -0.0735689849,\n",
       "                         0.0305600148,\n",
       "                         0.0774918497,\n",
       "                         -0.000532712147,\n",
       "                         0.0412204042,\n",
       "                         -0.0136107467,\n",
       "                         0.0778888464,\n",
       "                         -0.0708389,\n",
       "                         -0.0184928849,\n",
       "                         -0.0162294768,\n",
       "                         0.0862991437,\n",
       "                         0.0461444035,\n",
       "                         -0.00707692653,\n",
       "                         -0.0186980274,\n",
       "                         0.0153242694,\n",
       "                         -0.0491432,\n",
       "                         0.0655193,\n",
       "                         -0.0131543884,\n",
       "                         0.00838541,\n",
       "                         -0.00496623293,\n",
       "                         -0.0224883016,\n",
       "                         -0.0962273479,\n",
       "                         -0.00555555755,\n",
       "                         -0.0852558091,\n",
       "                         0.0726391748,\n",
       "                         0.0640648901,\n",
       "                         -0.00628849585,\n",
       "                         0.0796580836,\n",
       "                         0.0698465854,\n",
       "                         0.0393763743,\n",
       "                         -0.0257529672,\n",
       "                         0.0481217094,\n",
       "                         -0.118144616,\n",
       "                         -0.0246971212,\n",
       "                         0.0222743247,\n",
       "                         0.0740888193,\n",
       "                         -0.033116281,\n",
       "                         -4.35131682e-08,\n",
       "                         -0.0277213119,\n",
       "                         -0.0606015585,\n",
       "                         0.00444222288,\n",
       "                         0.0732293949,\n",
       "                         0.00935739186,\n",
       "                         -0.0494273603,\n",
       "                         -0.123020381,\n",
       "                         0.0630889758,\n",
       "                         -0.078958258,\n",
       "                         -0.0148287928,\n",
       "                         0.0936644673,\n",
       "                         -0.0301490054,\n",
       "                         -0.0147917913,\n",
       "                         -0.0264202729,\n",
       "                         0.0767479688,\n",
       "                         0.0035303745,\n",
       "                         0.00256126025,\n",
       "                         0.0703673139,\n",
       "                         -0.0294572469,\n",
       "                         0.0590421632,\n",
       "                         0.035971202,\n",
       "                         0.0322299302,\n",
       "                         -0.0598395206,\n",
       "                         0.0177661143,\n",
       "                         0.0561838634,\n",
       "                         -0.0122367013,\n",
       "                         0.00082150026,\n",
       "                         0.102465257,\n",
       "                         0.00103761291,\n",
       "                         -0.00828763098,\n",
       "                         -0.00327106123,\n",
       "                         -0.0276726726,\n",
       "                         -0.00787163153,\n",
       "                         -0.0387420394,\n",
       "                         0.0934206769,\n",
       "                         -0.00774609903,\n",
       "                         0.0171964169,\n",
       "                         -0.0265856348,\n",
       "                         -0.0226243176,\n",
       "                         0.0391598567,\n",
       "                         -0.0445420705,\n",
       "                         0.0273238327,\n",
       "                         -0.00644746469,\n",
       "                         0.0423464812,\n",
       "                         0.0776603445,\n",
       "                         -0.0436025709,\n",
       "                         -0.033857692,\n",
       "                         0.0199197903,\n",
       "                         -0.0449577756,\n",
       "                         -0.0229085647,\n",
       "                         -0.0298853219,\n",
       "                         0.0360560156,\n",
       "                         0.0358727574,\n",
       "                         0.0392569229,\n",
       "                         0.0298970193,\n",
       "                         0.0673222765,\n",
       "                         -0.00320119807,\n",
       "                         0.020736292,\n",
       "                         -0.0483931191,\n",
       "                         0.0206012391,\n",
       "                         0.0700160116,\n",
       "                         0.0345362313,\n",
       "                         -0.0354606584,\n",
       "                         -0.0162588544]},\n",
       "             {'id': 'fe2921b0-6533-4a3a-8f7a-ad40a8716390',\n",
       "              'score': 0.14487496,\n",
       "              'values': [0.0355774052,\n",
       "                         -0.0338303111,\n",
       "                         -0.0710638538,\n",
       "                         0.0208128765,\n",
       "                         -0.0521872602,\n",
       "                         -0.00388014666,\n",
       "                         -0.00167495862,\n",
       "                         0.000178060567,\n",
       "                         -0.0531763509,\n",
       "                         0.00472556846,\n",
       "                         0.0442132466,\n",
       "                         0.0282016248,\n",
       "                         0.0422495976,\n",
       "                         -0.0721543878,\n",
       "                         -0.050318,\n",
       "                         -0.00857530348,\n",
       "                         0.023164209,\n",
       "                         -0.00443919236,\n",
       "                         -0.0949335843,\n",
       "                         -0.00850659143,\n",
       "                         -0.0262034815,\n",
       "                         -0.0137551669,\n",
       "                         0.0582562126,\n",
       "                         0.00848874,\n",
       "                         -0.0133165671,\n",
       "                         0.0462909266,\n",
       "                         0.0127753168,\n",
       "                         -0.00659425091,\n",
       "                         0.0580861047,\n",
       "                         0.00606112694,\n",
       "                         0.0341780074,\n",
       "                         0.207699433,\n",
       "                         0.0589307323,\n",
       "                         0.0443259478,\n",
       "                         -0.0321162678,\n",
       "                         0.0114576211,\n",
       "                         0.0717384294,\n",
       "                         0.00551485,\n",
       "                         -0.00367287407,\n",
       "                         0.100295618,\n",
       "                         -0.0315915979,\n",
       "                         0.0595123805,\n",
       "                         0.109640516,\n",
       "                         0.0397135541,\n",
       "                         0.0293528382,\n",
       "                         0.0525847562,\n",
       "                         -0.0558346137,\n",
       "                         -0.100900941,\n",
       "                         -0.0806959793,\n",
       "                         -0.0407814048,\n",
       "                         -0.0699816421,\n",
       "                         -0.012852,\n",
       "                         -0.012928199,\n",
       "                         0.0483824797,\n",
       "                         0.0232011378,\n",
       "                         -0.046697244,\n",
       "                         0.0220987517,\n",
       "                         -0.00475649722,\n",
       "                         -0.0117573105,\n",
       "                         0.0293867663,\n",
       "                         -0.0422267839,\n",
       "                         -0.0846838951,\n",
       "                         -0.0464865752,\n",
       "                         0.00389142963,\n",
       "                         0.0312291812,\n",
       "                         -0.0228359737,\n",
       "                         -0.0480729155,\n",
       "                         0.00426113652,\n",
       "                         -0.0309768822,\n",
       "                         -0.0552295558,\n",
       "                         -0.0799614936,\n",
       "                         0.0562138893,\n",
       "                         -0.05650324,\n",
       "                         0.0224785358,\n",
       "                         0.0657178462,\n",
       "                         0.00311541068,\n",
       "                         -0.0372453108,\n",
       "                         -0.016408043,\n",
       "                         0.060140118,\n",
       "                         -0.114134714,\n",
       "                         0.0158467162,\n",
       "                         -0.0214484818,\n",
       "                         0.00994951557,\n",
       "                         0.00880689,\n",
       "                         0.0815879181,\n",
       "                         -0.0319834165,\n",
       "                         0.1048977,\n",
       "                         -0.00158012437,\n",
       "                         -0.0571811236,\n",
       "                         0.00401519332,\n",
       "                         0.0683008507,\n",
       "                         0.0688433,\n",
       "                         0.0312570706,\n",
       "                         0.0113644376,\n",
       "                         -0.0818265527,\n",
       "                         0.0888708681,\n",
       "                         0.0236329306,\n",
       "                         -0.0751614273,\n",
       "                         0.0623593815,\n",
       "                         0.0275479816,\n",
       "                         0.00781673845,\n",
       "                         0.0241614189,\n",
       "                         -0.0260468516,\n",
       "                         0.0599518456,\n",
       "                         -0.0527940392,\n",
       "                         -0.0544354841,\n",
       "                         0.0558968484,\n",
       "                         0.0320224203,\n",
       "                         0.091615133,\n",
       "                         -0.115630627,\n",
       "                         -0.0208289512,\n",
       "                         0.0509081893,\n",
       "                         -0.0609444045,\n",
       "                         -0.0578681529,\n",
       "                         0.00738865091,\n",
       "                         0.011598587,\n",
       "                         -0.0431910679,\n",
       "                         0.0411748029,\n",
       "                         0.0439091772,\n",
       "                         0.0211563483,\n",
       "                         -0.000819618348,\n",
       "                         -0.0158437323,\n",
       "                         -0.00934031513,\n",
       "                         -0.0448362939,\n",
       "                         0.014325439,\n",
       "                         -0.0130994832,\n",
       "                         -0.10362643,\n",
       "                         1.60249704e-34,\n",
       "                         -0.00435826741,\n",
       "                         -0.0175804533,\n",
       "                         -0.0527415425,\n",
       "                         -0.0220873319,\n",
       "                         -0.0304268543,\n",
       "                         -0.0125020547,\n",
       "                         0.031380374,\n",
       "                         0.000948464964,\n",
       "                         0.0559014417,\n",
       "                         -0.00646239705,\n",
       "                         -0.0388382114,\n",
       "                         0.093859829,\n",
       "                         -0.00213852013,\n",
       "                         0.0912056193,\n",
       "                         0.0830856562,\n",
       "                         0.0413822,\n",
       "                         -0.0515220799,\n",
       "                         0.0693780705,\n",
       "                         -0.0627347231,\n",
       "                         -0.0379299894,\n",
       "                         0.120010801,\n",
       "                         -0.0220936034,\n",
       "                         0.0714902431,\n",
       "                         -0.0465485193,\n",
       "                         -0.0313302204,\n",
       "                         -0.00475471141,\n",
       "                         0.0262401011,\n",
       "                         0.0650045127,\n",
       "                         -0.0424229167,\n",
       "                         0.0167058241,\n",
       "                         -0.0244850013,\n",
       "                         0.0274692,\n",
       "                         -0.0666658,\n",
       "                         0.0394375399,\n",
       "                         0.0238373745,\n",
       "                         0.00392118143,\n",
       "                         0.00311315595,\n",
       "                         0.0642954558,\n",
       "                         0.0233710166,\n",
       "                         -0.00887772255,\n",
       "                         0.0315910466,\n",
       "                         0.0032262262,\n",
       "                         0.083230868,\n",
       "                         -0.0244141612,\n",
       "                         0.022072399,\n",
       "                         0.0131749222,\n",
       "                         0.103691638,\n",
       "                         -0.0403532125,\n",
       "                         -0.037951421,\n",
       "                         0.00144498993,\n",
       "                         -0.0417186916,\n",
       "                         -0.0205197353,\n",
       "                         0.0832566619,\n",
       "                         -0.0312456079,\n",
       "                         0.0651689,\n",
       "                         0.0943335891,\n",
       "                         0.00638318295,\n",
       "                         0.0102183977,\n",
       "                         -0.0197218601,\n",
       "                         0.0933624953,\n",
       "                         -0.0914069936,\n",
       "                         -0.0283647235,\n",
       "                         0.0053122323,\n",
       "                         0.0505243875,\n",
       "                         0.00250677089,\n",
       "                         0.0499987267,\n",
       "                         -0.0520169698,\n",
       "                         -0.0351718888,\n",
       "                         0.101990901,\n",
       "                         -0.0292464104,\n",
       "                         0.0373150036,\n",
       "                         0.0151529517,\n",
       "                         -0.0743288323,\n",
       "                         0.00358313206,\n",
       "                         0.00755921705,\n",
       "                         -0.0597572662,\n",
       "                         -0.0129385246,\n",
       "                         0.0434638597,\n",
       "                         -0.0666508526,\n",
       "                         0.0226279888,\n",
       "                         0.0258129817,\n",
       "                         0.0254088473,\n",
       "                         -0.0355729,\n",
       "                         -0.0823730677,\n",
       "                         -0.0927601,\n",
       "                         -0.0584222898,\n",
       "                         0.0437868536,\n",
       "                         -0.0727840737,\n",
       "                         -0.00168219605,\n",
       "                         -0.0071784351,\n",
       "                         -0.104729533,\n",
       "                         -0.0128747867,\n",
       "                         -0.00515430607,\n",
       "                         -0.055435393,\n",
       "                         0.0500093699,\n",
       "                         -2.0984409e-33,\n",
       "                         0.00100985507,\n",
       "                         0.078677319,\n",
       "                         -0.107596695,\n",
       "                         0.080659233,\n",
       "                         0.00210527657,\n",
       "                         0.0398255736,\n",
       "                         -0.00496102683,\n",
       "                         0.0525899,\n",
       "                         -0.0205639359,\n",
       "                         -0.00277206092,\n",
       "                         0.0405344516,\n",
       "                         -0.109072901,\n",
       "                         -0.0366952419,\n",
       "                         -0.0899453238,\n",
       "                         -0.0116823399,\n",
       "                         0.0112963822,\n",
       "                         -0.0743046477,\n",
       "                         -0.0337118097,\n",
       "                         -0.00995006133,\n",
       "                         0.000784705277,\n",
       "                         0.0139551992,\n",
       "                         -0.0243347138,\n",
       "                         -0.0573265813,\n",
       "                         0.035714522,\n",
       "                         -0.021618275,\n",
       "                         -0.0326682962,\n",
       "                         -0.0472946204,\n",
       "                         -0.00878233463,\n",
       "                         0.0155446697,\n",
       "                         0.0547518767,\n",
       "                         0.0393702909,\n",
       "                         -0.123187281,\n",
       "                         -0.0570420325,\n",
       "                         0.0616550222,\n",
       "                         0.00209054095,\n",
       "                         -0.0383944,\n",
       "                         0.131790146,\n",
       "                         -0.059564732,\n",
       "                         -0.0225252286,\n",
       "                         0.0865238681,\n",
       "                         0.0339550823,\n",
       "                         0.0742365047,\n",
       "                         -0.0743322596,\n",
       "                         0.0274072122,\n",
       "                         0.0295015238,\n",
       "                         0.0151394429,\n",
       "                         -0.0269733761,\n",
       "                         -0.0052594468,\n",
       "                         0.000621316896,\n",
       "                         -0.0735043436,\n",
       "                         0.0041292496,\n",
       "                         0.0188636184,\n",
       "                         0.0329314247,\n",
       "                         -0.0343144536,\n",
       "                         0.0405943692,\n",
       "                         -0.00650719972,\n",
       "                         -0.0105031636,\n",
       "                         0.0155418413,\n",
       "                         0.0444257334,\n",
       "                         0.045484852,\n",
       "                         0.0120066721,\n",
       "                         -0.0476476029,\n",
       "                         0.0115388455,\n",
       "                         0.0514065921,\n",
       "                         -0.0316602699,\n",
       "                         -0.0280936696,\n",
       "                         -0.0282554552,\n",
       "                         0.022305306,\n",
       "                         -0.0222676042,\n",
       "                         0.0270240679,\n",
       "                         -0.0233952347,\n",
       "                         -0.0603863336,\n",
       "                         -0.0257632,\n",
       "                         -0.0620419607,\n",
       "                         -0.124925815,\n",
       "                         0.0239680111,\n",
       "                         0.0405140482,\n",
       "                         -0.0755548924,\n",
       "                         -0.0501703508,\n",
       "                         0.00839283131,\n",
       "                         0.0272665489,\n",
       "                         -0.086371325,\n",
       "                         0.00148254295,\n",
       "                         0.079877384,\n",
       "                         -0.0509523712,\n",
       "                         0.0955577269,\n",
       "                         0.115807,\n",
       "                         0.0064852247,\n",
       "                         -0.0197228249,\n",
       "                         -0.0637380257,\n",
       "                         -0.00657189498,\n",
       "                         -0.037730068,\n",
       "                         -0.0874558464,\n",
       "                         0.0280471295,\n",
       "                         -0.0151042184,\n",
       "                         -4.70690047e-08,\n",
       "                         -0.027348306,\n",
       "                         -0.0191891249,\n",
       "                         -0.0382189937,\n",
       "                         0.00481361197,\n",
       "                         -0.00353977084,\n",
       "                         0.00400874903,\n",
       "                         -0.0153732104,\n",
       "                         0.147540286,\n",
       "                         -0.0839153379,\n",
       "                         0.10707245,\n",
       "                         0.0717786551,\n",
       "                         0.0380595736,\n",
       "                         -0.094980225,\n",
       "                         0.066652596,\n",
       "                         0.0600237958,\n",
       "                         0.00539709395,\n",
       "                         -0.00634787604,\n",
       "                         0.0337801203,\n",
       "                         -0.00764705148,\n",
       "                         0.0458239317,\n",
       "                         0.10521283,\n",
       "                         0.0170255378,\n",
       "                         0.0452085361,\n",
       "                         -0.0898729414,\n",
       "                         -0.0189328846,\n",
       "                         -0.0361786298,\n",
       "                         0.0158081707,\n",
       "                         0.0328627899,\n",
       "                         -0.0234524123,\n",
       "                         0.00575187,\n",
       "                         0.0722384527,\n",
       "                         0.00914134551,\n",
       "                         0.0238105133,\n",
       "                         -0.101943955,\n",
       "                         0.0144560598,\n",
       "                         0.00796421058,\n",
       "                         -0.0462165214,\n",
       "                         -0.0482663885,\n",
       "                         0.00678354781,\n",
       "                         -0.00329591427,\n",
       "                         -0.0633149445,\n",
       "                         0.0105871623,\n",
       "                         -0.00913118385,\n",
       "                         -0.00571374735,\n",
       "                         0.0770207942,\n",
       "                         -0.00219943328,\n",
       "                         0.012125616,\n",
       "                         0.0261854827,\n",
       "                         -0.00249049324,\n",
       "                         0.0159670897,\n",
       "                         -0.00670271972,\n",
       "                         0.038589444,\n",
       "                         -0.0451760516,\n",
       "                         -0.0537476242,\n",
       "                         0.0391764492,\n",
       "                         0.0971976444,\n",
       "                         -0.0112376157,\n",
       "                         -0.077747874,\n",
       "                         -0.0747460723,\n",
       "                         -0.00749472249,\n",
       "                         0.0283818394,\n",
       "                         0.0126036759,\n",
       "                         -0.0343590342,\n",
       "                         -0.0309982188]},\n",
       "             {'id': 'da8e6426-b797-4c0e-8792-3a518861014a',\n",
       "              'score': 0.132136628,\n",
       "              'values': [-0.0729902238,\n",
       "                         -0.0821863487,\n",
       "                         0.00421859883,\n",
       "                         -0.0142973922,\n",
       "                         0.0198314656,\n",
       "                         -0.0777302459,\n",
       "                         0.0228134189,\n",
       "                         0.0299852137,\n",
       "                         0.0251985695,\n",
       "                         -0.0407316834,\n",
       "                         -0.0282133948,\n",
       "                         0.00905822497,\n",
       "                         -0.00654349755,\n",
       "                         0.044831153,\n",
       "                         0.103816,\n",
       "                         0.0214953888,\n",
       "                         0.0660796613,\n",
       "                         0.0202642437,\n",
       "                         -0.0203328803,\n",
       "                         -0.0853713676,\n",
       "                         0.030579254,\n",
       "                         0.0522750765,\n",
       "                         0.0318511873,\n",
       "                         -0.00662163179,\n",
       "                         0.0627913103,\n",
       "                         -0.00793731399,\n",
       "                         0.0308058504,\n",
       "                         -0.0658578426,\n",
       "                         0.0820893198,\n",
       "                         0.0324951634,\n",
       "                         0.00471738679,\n",
       "                         0.0346342,\n",
       "                         0.00585202035,\n",
       "                         0.09090437,\n",
       "                         -0.0656623617,\n",
       "                         0.13276501,\n",
       "                         -0.0750548169,\n",
       "                         0.0211725384,\n",
       "                         -0.0207912866,\n",
       "                         0.0152521608,\n",
       "                         -0.0847515836,\n",
       "                         -0.0591590218,\n",
       "                         0.0115453443,\n",
       "                         -0.00956355408,\n",
       "                         0.0680434257,\n",
       "                         -0.0200837124,\n",
       "                         -0.063938722,\n",
       "                         -0.00296395,\n",
       "                         -0.0932243168,\n",
       "                         -0.0536833741,\n",
       "                         -0.0687262565,\n",
       "                         -0.00265954086,\n",
       "                         -0.0066133989,\n",
       "                         0.0367141515,\n",
       "                         1.83261127e-05,\n",
       "                         0.0648128539,\n",
       "                         0.0476776958,\n",
       "                         -0.0133936778,\n",
       "                         0.0267013088,\n",
       "                         -0.0522025935,\n",
       "                         0.00879399106,\n",
       "                         -0.00376769644,\n",
       "                         -0.0696577281,\n",
       "                         -0.029449638,\n",
       "                         -0.016097283,\n",
       "                         0.02620277,\n",
       "                         0.00236041658,\n",
       "                         0.0295396987,\n",
       "                         0.0181242339,\n",
       "                         -0.0850196779,\n",
       "                         -0.033403866,\n",
       "                         0.0437368415,\n",
       "                         -0.034264531,\n",
       "                         0.042351909,\n",
       "                         0.049040392,\n",
       "                         0.0288683847,\n",
       "                         0.0673972368,\n",
       "                         0.0141636431,\n",
       "                         0.0166613795,\n",
       "                         0.0366908461,\n",
       "                         0.0384618156,\n",
       "                         0.0424614549,\n",
       "                         0.0837925598,\n",
       "                         0.0615034699,\n",
       "                         -0.02715181,\n",
       "                         -0.0351424925,\n",
       "                         0.0623363554,\n",
       "                         0.0941781774,\n",
       "                         -0.0721275136,\n",
       "                         0.0714090168,\n",
       "                         -0.0601607226,\n",
       "                         -0.0553339757,\n",
       "                         0.0922283381,\n",
       "                         0.0543088764,\n",
       "                         -0.0407149941,\n",
       "                         -0.0735842139,\n",
       "                         -0.0446670055,\n",
       "                         -0.0515547357,\n",
       "                         -0.0337670296,\n",
       "                         0.0208841767,\n",
       "                         -0.0275712758,\n",
       "                         -0.0145832896,\n",
       "                         -0.0235917959,\n",
       "                         -0.0214943886,\n",
       "                         -0.0299567264,\n",
       "                         -0.0516841896,\n",
       "                         0.043463733,\n",
       "                         -0.00472378964,\n",
       "                         0.0105906604,\n",
       "                         0.0104071377,\n",
       "                         -0.0112202773,\n",
       "                         -0.0485363,\n",
       "                         0.0108746281,\n",
       "                         -0.0832001641,\n",
       "                         -0.00446675159,\n",
       "                         0.0343345739,\n",
       "                         -0.0387115777,\n",
       "                         0.0131673701,\n",
       "                         -0.0238552615,\n",
       "                         -0.00859461073,\n",
       "                         0.0687086657,\n",
       "                         0.00732508767,\n",
       "                         0.008940842,\n",
       "                         -0.0175372642,\n",
       "                         0.00886396505,\n",
       "                         -0.021492742,\n",
       "                         -0.0352969766,\n",
       "                         1.08152864e-33,\n",
       "                         0.0476295091,\n",
       "                         -0.0283530504,\n",
       "                         0.0148427607,\n",
       "                         0.0671270937,\n",
       "                         0.0243156962,\n",
       "                         0.0657140464,\n",
       "                         -0.0392086357,\n",
       "                         -0.019316012,\n",
       "                         0.0666691363,\n",
       "                         -0.0200585034,\n",
       "                         0.024317177,\n",
       "                         0.0845707953,\n",
       "                         -0.0898134,\n",
       "                         0.0910415202,\n",
       "                         -0.0153356967,\n",
       "                         -0.0181542374,\n",
       "                         -0.0784314722,\n",
       "                         0.0256343056,\n",
       "                         0.0327174589,\n",
       "                         -0.00913956948,\n",
       "                         0.00852308702,\n",
       "                         -0.00509841088,\n",
       "                         0.0253952388,\n",
       "                         0.0691711605,\n",
       "                         0.0256049875,\n",
       "                         0.0594221,\n",
       "                         0.0404836312,\n",
       "                         -0.0977784768,\n",
       "                         0.00853653066,\n",
       "                         0.00616328605,\n",
       "                         -0.119439006,\n",
       "                         -0.0374697931,\n",
       "                         -0.0102230962,\n",
       "                         0.00159347442,\n",
       "                         0.0165325105,\n",
       "                         -0.0444083065,\n",
       "                         0.0323657505,\n",
       "                         -0.10612563,\n",
       "                         0.0261340234,\n",
       "                         0.0208538957,\n",
       "                         -0.0403599292,\n",
       "                         -0.038258072,\n",
       "                         0.0671813414,\n",
       "                         -0.110416085,\n",
       "                         0.0492802076,\n",
       "                         -0.0104981791,\n",
       "                         0.0210690349,\n",
       "                         -0.0160605703,\n",
       "                         -0.0542623736,\n",
       "                         0.0471469462,\n",
       "                         -0.0536630899,\n",
       "                         0.0498029441,\n",
       "                         -0.0391801968,\n",
       "                         0.0275853481,\n",
       "                         0.0198411,\n",
       "                         -0.0364843681,\n",
       "                         0.0247703772,\n",
       "                         0.030451363,\n",
       "                         0.0329755135,\n",
       "                         -0.00210395502,\n",
       "                         -0.0200693849,\n",
       "                         0.0117894094,\n",
       "                         0.00484167179,\n",
       "                         -0.0278961752,\n",
       "                         0.00363660068,\n",
       "                         -0.0448730141,\n",
       "                         -0.0333468504,\n",
       "                         -0.0628974065,\n",
       "                         0.0520916879,\n",
       "                         0.0231272057,\n",
       "                         -0.0466888808,\n",
       "                         0.047686968,\n",
       "                         -0.0671620071,\n",
       "                         0.0176137388,\n",
       "                         -0.0462698974,\n",
       "                         -0.0269425046,\n",
       "                         0.0177966338,\n",
       "                         0.0337402,\n",
       "                         0.0339493752,\n",
       "                         -0.0105541376,\n",
       "                         -0.0806421936,\n",
       "                         0.0171688683,\n",
       "                         -0.0510905609,\n",
       "                         -0.0404657088,\n",
       "                         -0.0178697314,\n",
       "                         0.00398574863,\n",
       "                         -0.0222517438,\n",
       "                         -0.0541757196,\n",
       "                         -0.0392749123,\n",
       "                         0.0143462,\n",
       "                         -0.146012232,\n",
       "                         -0.0134976879,\n",
       "                         -0.0101712719,\n",
       "                         0.0287942085,\n",
       "                         0.0355112962,\n",
       "                         -1.53147638e-33,\n",
       "                         -0.055540055,\n",
       "                         0.0948603824,\n",
       "                         -0.0711140931,\n",
       "                         0.0851863548,\n",
       "                         0.0160538703,\n",
       "                         -0.08307942,\n",
       "                         0.0735647604,\n",
       "                         0.0628121868,\n",
       "                         0.058828298,\n",
       "                         0.0739901736,\n",
       "                         -0.0382989347,\n",
       "                         -0.0446979925,\n",
       "                         0.0170188062,\n",
       "                         -0.0168040078,\n",
       "                         0.0748459697,\n",
       "                         -0.0214428212,\n",
       "                         -0.0798559114,\n",
       "                         -0.0862678438,\n",
       "                         -0.0480587855,\n",
       "                         0.0432873331,\n",
       "                         0.047622595,\n",
       "                         0.131932899,\n",
       "                         -0.162511319,\n",
       "                         -0.0084413141,\n",
       "                         0.0178627092,\n",
       "                         0.0163208954,\n",
       "                         -0.061933063,\n",
       "                         0.0285484698,\n",
       "                         0.0658272728,\n",
       "                         0.0244296677,\n",
       "                         0.0187090058,\n",
       "                         0.00629063323,\n",
       "                         0.0334124304,\n",
       "                         0.00375842606,\n",
       "                         -0.0110188881,\n",
       "                         -0.0127100898,\n",
       "                         0.144615203,\n",
       "                         -0.00476351567,\n",
       "                         -0.074396193,\n",
       "                         0.0289707575,\n",
       "                         0.0747040957,\n",
       "                         -0.0467147864,\n",
       "                         -0.0518873744,\n",
       "                         0.0202804785,\n",
       "                         -0.0343169607,\n",
       "                         -0.0437507853,\n",
       "                         -0.0805578455,\n",
       "                         -0.0491464175,\n",
       "                         0.0508625582,\n",
       "                         0.00618102215,\n",
       "                         0.0052275015,\n",
       "                         -0.0176713075,\n",
       "                         0.0194482617,\n",
       "                         -0.0667946637,\n",
       "                         -0.0375998095,\n",
       "                         -0.129360408,\n",
       "                         0.0682207942,\n",
       "                         -0.0110814264,\n",
       "                         -0.0414767452,\n",
       "                         0.0116333356,\n",
       "                         -0.0102585461,\n",
       "                         -0.046426028,\n",
       "                         0.163575366,\n",
       "                         -0.0232373718,\n",
       "                         -0.0142444121,\n",
       "                         -0.0991499349,\n",
       "                         -0.0379663147,\n",
       "                         0.0504634231,\n",
       "                         -0.00538498536,\n",
       "                         -0.0172545109,\n",
       "                         0.00354956137,\n",
       "                         -0.0169949681,\n",
       "                         0.0034703305,\n",
       "                         -0.0201043785,\n",
       "                         0.0397519022,\n",
       "                         0.0308942925,\n",
       "                         -0.0508768074,\n",
       "                         0.021313807,\n",
       "                         0.0331287868,\n",
       "                         -0.0256483741,\n",
       "                         0.0191520508,\n",
       "                         -0.0610350594,\n",
       "                         0.0708607808,\n",
       "                         0.0908059925,\n",
       "                         0.0516631901,\n",
       "                         0.0411142521,\n",
       "                         0.09308777,\n",
       "                         0.0371257439,\n",
       "                         0.0211148281,\n",
       "                         0.0594410785,\n",
       "                         -0.0967402458,\n",
       "                         0.100335792,\n",
       "                         0.0235220678,\n",
       "                         0.0801669583,\n",
       "                         -0.037886858,\n",
       "                         -4.0532985e-08,\n",
       "                         -0.0587567799,\n",
       "                         -0.0476691686,\n",
       "                         -0.0259918515,\n",
       "                         0.0222719386,\n",
       "                         -0.0349707529,\n",
       "                         -0.00649984181,\n",
       "                         0.0107512511,\n",
       "                         0.0277657416,\n",
       "                         -0.0667841509,\n",
       "                         0.0362540819,\n",
       "                         0.0278159846,\n",
       "                         -0.0154677536,\n",
       "                         -0.0608003028,\n",
       "                         -0.0172230955,\n",
       "                         0.0814171955,\n",
       "                         0.0152878165,\n",
       "                         0.0234167,\n",
       "                         -0.000154960988,\n",
       "                         -8.5281732e-05,\n",
       "                         -0.0255654212,\n",
       "                         0.0725128949,\n",
       "                         0.0365625,\n",
       "                         -0.0750240162,\n",
       "                         0.0177404173,\n",
       "                         -0.0368493125,\n",
       "                         -0.0692799166,\n",
       "                         0.00188915094,\n",
       "                         0.0708122253,\n",
       "                         -0.0737151578,\n",
       "                         0.0697762072,\n",
       "                         0.016052736,\n",
       "                         0.078324683,\n",
       "                         0.0620278753,\n",
       "                         0.00191772031,\n",
       "                         0.0227400269,\n",
       "                         -0.00272031408,\n",
       "                         0.0315410458,\n",
       "                         -0.0304198265,\n",
       "                         -0.000789327431,\n",
       "                         0.000547970238,\n",
       "                         -0.00403951667,\n",
       "                         0.0363668352,\n",
       "                         -0.0944764838,\n",
       "                         -0.0260604173,\n",
       "                         -0.0281655416,\n",
       "                         -0.00233481801,\n",
       "                         -0.00214086543,\n",
       "                         -0.150255069,\n",
       "                         -0.0734180883,\n",
       "                         0.0310797505,\n",
       "                         -0.0419391245,\n",
       "                         0.04583,\n",
       "                         -0.0520022437,\n",
       "                         0.0602486394,\n",
       "                         0.10619054,\n",
       "                         0.043052718,\n",
       "                         -0.00630172295,\n",
       "                         -0.0184888393,\n",
       "                         0.0186796933,\n",
       "                         0.0551078245,\n",
       "                         -0.0722106546,\n",
       "                         0.128068149,\n",
       "                         0.0638439432,\n",
       "                         0.00328680268]}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector = embeddings_model.embed_query(\"What is deepseek\")\n",
    "dense_index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    include_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc50286-ac31-41d4-85fb-78ba75968171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
